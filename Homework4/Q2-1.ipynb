{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q2-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6MlHCEAdZPy1","colab_type":"text"},"source":["**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n","So now you could mount your data to this ipynb!"]},{"cell_type":"code","metadata":{"id":"UGAXY5HMYjzL","colab_type":"code","colab":{}},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTBYCMcpZoA8","colab_type":"code","colab":{}},"source":["# if you mount Google drive correctly, the following commands should be able to executed correctly\n","!ls /content/drive/\n","%cd \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/\"\n","%cd \"CamVid\"\n","\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfWmPZKyZ8gA","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import utils\n","import torchvision\n","from torchvision import models\n","from torchvision.models.vgg import VGG\n","import random\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import time\n","import sys\n","import os\n","from os import path\n","\n","from PIL import Image\n","import pandas as pd\n","from torchvision.models.vgg import VGG\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lj4LYnvgBT1T","colab_type":"code","colab":{}},"source":["seed = 1450\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMzL2KhcaI9u","colab_type":"code","outputId":"e746386a-9cca-4ede-d206-041896b93561","executionInfo":{"status":"ok","timestamp":1576771320975,"user_tz":-480,"elapsed":111207,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","root_dir   = \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/\"\n","train_file = os.path.join(root_dir, \"train.csv\")\n","val_file   = os.path.join(root_dir, \"val.csv\")\n","\n","print(\"training csv exits:{}\".format(path.exists(train_file)))\n","print(\"validation csv exits:{}\".format(path.exists(val_file)))\n","\n","# the folder to save results for comparison\n","folder_to_save_validation_result = '/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/result_comparision/' \n","\n","if os.path.isdir(folder_to_save_validation_result) == False:\n","    os.mkdir(folder_to_save_validation_result)\n","\n","\n","# the number of segmentation classes\n","num_class = 12 # 32 for original CamVid\n","means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n","\n","h, w = 256, 256\n","train_h = 256\n","train_w = 256\n","val_h = 256\n","val_w = 256\n","\n","## parameters for Solver-Adam in this example\n","batch_size = 6 #\n","epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n","lr         = 1e-4    # achieved besty results \n","step_size  = 100 # Won't work when epochs <=100\n","gamma      = 0.5 # \n","#\n","\n","## index for validation images\n","global_index = 0\n","\n","# pixel accuracy and mIOU list \n","pixel_acc_list = []\n","mIOU_list = []\n","\n","use_gpu = torch.cuda.is_available()\n","num_gpu = list(range(torch.cuda.device_count()))\n","\n","class CamVidDataset(Dataset):\n","\n","    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n","        self.data      = pd.read_csv(csv_file)\n","        self.means     = means\n","        self.n_class   = n_class\n","        self.flip_rate = flip_rate       \n","\n","        self.resize_h = h\n","        self.resize_w = w        \n","        \n","        if phase == 'train':\n","            self.new_h = train_h\n","            self.new_w = train_w\n","            self.crop = crop\n","        elif phase == 'val':\n","            self.flip_rate = 0.\n","            self.crop = False # False\n","            self.new_h = val_h\n","            self.new_w = val_w\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_name   = self.data.iloc[idx, 0]                \n","        img_name = root_dir  + img_name                        \n","        img = Image.open(img_name).convert('RGB')  \n","\n","        label_name = self.data.iloc[idx, 1]        \n","        label_name = root_dir  + label_name                       \n","        label_image = Image.open(label_name)\n","        label = np.asarray(label_image)\n","\n","        # In training mode, the crop strategy is random-shift crop.\n","        # In validation model, it is center crop.\n","        if self.crop:            \n","            w, h = img.size\n","            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n","            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n","\n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","        else:            \n","            w, h = img.size\n","            A_x_offset = int((w - self.new_w)/2)\n","            A_y_offset = int((h - self.new_h)/2)\n","            \n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","\n","            label_image_h, label_image_w = label_image.size\n","\n","        # we could try to revise the values in label for reducing the number of segmentation classes\n","        label = np.array(label_image)              \n","\n","        if random.random() < self.flip_rate:\n","            img   = np.fliplr(img)\n","            label = np.fliplr(label)\n","        \n","        # reduce mean in terms of BGR\n","        img = np.transpose(img, (2, 0, 1)) / 255.\n","        img[0] -= self.means[0]\n","        img[1] -= self.means[1]\n","        img[2] -= self.means[2]\n","\n","        # convert to tensor\n","        img = torch.from_numpy(img.copy()).float()\n","        label = torch.from_numpy(label.copy()).long()\n","\n","        # create one-hot encoding\n","        h, w = label.size()\n","        target = torch.zeros(self.n_class, h, w)\n","        for c in range(self.n_class):\n","            target[c][label == c] = 1\n","\n","        sample = {'X': img, 'Y': target, 'l': label}\n","\n","        return sample\n","\n","\n","train_data = CamVidDataset(csv_file=train_file, phase='train')\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n","\n","val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n","val_loader = DataLoader(val_data, batch_size=1, num_workers=8)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["training csv exits:True\n","validation csv exits:True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4h-a5moWhLhF","colab_type":"code","colab":{}},"source":["# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n","cfg = {\n","    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","ranges = {\n","    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n","    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n","    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n","    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n","}\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)\n","\n","class VGGNet(VGG):\n","    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n","        super().__init__(make_layers(cfg[model]))\n","        self.ranges = ranges[model]\n","\n","        if pretrained:            \n","            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n","\n","        if not requires_grad:\n","            for param in super().parameters():\n","                param.requires_grad = False\n","\n","        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n","            del self.classifier\n","\n","        if show_params:\n","            for name, param in self.named_parameters():\n","                print(name, param.size())\n","\n","    def forward(self, x):\n","        output = {}\n","\n","        # get the output of each maxpooling layer (5 maxpool in VGG net)\n","        for idx in range(len(self.ranges)):\n","            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n","                x = self.features[layer](x)\n","            output[\"x%d\"%(idx+1)] = x\n","\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZWlA75uj4u1","colab_type":"code","colab":{}},"source":["class FCN8s(nn.Module):\n","    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n","    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu    = nn.ReLU(inplace=True)\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn1     = nn.BatchNorm2d(512)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn2     = nn.BatchNorm2d(256)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn3     = nn.BatchNorm2d(128)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn4     = nn.BatchNorm2d(64)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn5     = nn.BatchNorm2d(32)\n","        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.pretrained_net(x)\n","        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n","        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n","        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n","\n","        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n","        score = self.bn1(score)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n","        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n","        score = self.bn2(score)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n","        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n","        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n","        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n","        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n","\n","        return score  # size=(N, n_class, x.H/1, x.W/1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_d5x1O2j53K","colab_type":"code","outputId":"8b735c44-bf69-4001-d7f3-62714d8ecc0e","executionInfo":{"status":"ok","timestamp":1576771332053,"user_tz":-480,"elapsed":122273,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":972}},"source":["# load pretrained weights and define FCN8s\n","vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n","fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n","\n","ts = time.time()\n","vgg_model = vgg_model.cuda()\n","fcn_model = fcn_model.cuda()\n","fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n","print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma) \n","\n","print(fcn_model)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:02<00:00, 238MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Finish cuda loading, time elapsed 4.86567759513855\n","DataParallel(\n","  (module): FCN8s(\n","    (pretrained_net): VGGNet(\n","      (features): Sequential(\n","        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): ReLU(inplace=True)\n","        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (6): ReLU(inplace=True)\n","        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (8): ReLU(inplace=True)\n","        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (11): ReLU(inplace=True)\n","        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (13): ReLU(inplace=True)\n","        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (15): ReLU(inplace=True)\n","        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (18): ReLU(inplace=True)\n","        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (20): ReLU(inplace=True)\n","        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (22): ReLU(inplace=True)\n","        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (25): ReLU(inplace=True)\n","        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (27): ReLU(inplace=True)\n","        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (29): ReLU(inplace=True)\n","        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    )\n","    (relu): ReLU(inplace=True)\n","    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (classifier): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oExd6u7kkLw6","colab_type":"code","colab":{}},"source":["def val(epoch):\n","    fcn_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","                    \n","    \n","    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n","        if use_gpu:\n","            inputs = Variable(batch['X'].cuda())\n","        else:\n","            inputs = Variable(batch['X'])        \n","\n","        output = fcn_model(inputs)                                \n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            print('---------iter={}'.format(iter))\n","            # generate images\n","            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n","            image = images[0,:,:]        \n","            save_result_comparison(batch['X'], image)\n","                            \n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape                \n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n","        target = batch['l'].cpu().numpy().reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t))\n","            pixel_accs.append(pixel_acc(p, t))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n","    \n","    global pixel_acc_list\n","    global mIOU_list\n","    \n","    pixel_acc_list.append(pixel_accs)\n","    mIOU_list.append(np.nanmean(ious))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUjPeffKbm36","colab_type":"code","colab":{}},"source":["def train():\n","    for epoch in range(epochs):\n","        scheduler.step()\n","\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","\n","            if use_gpu:\n","                inputs = Variable(batch['X'].cuda())\n","                labels = Variable(batch['Y'].cuda())\n","            else:\n","                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n","\n","            outputs = fcn_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n","        \n","\n","        val(epoch)\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)        \n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qj9aXgiYkYfW","colab_type":"code","colab":{}},"source":["def save_result_comparison(input_np, output_np):\n","    means     = np.array([103.939, 116.779, 123.68]) / 255.\n","    \n","    global global_index\n","    \n","    original_im_RGB = np.zeros((256,256,3))    \n","    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n","    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n","    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n","    \n","    im_seg_RGB = np.zeros((256,256,3))\n","\n","    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n","    for i in range(256):\n","        for j in range(256):\n","            if output_np[i,j] == 0:\n","                im_seg_RGB[i,j,:] = [128, 128, 128]\n","            elif output_np[i,j] == 1:  \n","                im_seg_RGB[i,j,:] = [128, 0, 0]\n","            elif output_np[i,j] == 2:  \n","                im_seg_RGB[i,j,:] = [192, 192, 128]    \n","            elif output_np[i,j] == 3:  \n","                im_seg_RGB[i,j,:] = [128, 64, 128]    \n","            elif output_np[i,j] == 4:  \n","                im_seg_RGB[i,j,:] = [0, 0, 192]    \n","            elif output_np[i,j] == 5:  \n","                im_seg_RGB[i,j,:] = [128, 128, 0]    \n","            elif output_np[i,j] == 6:  \n","                im_seg_RGB[i,j,:] = [192, 128, 128]    \n","            elif output_np[i,j] == 7:  \n","                im_seg_RGB[i,j,:] = [64, 64, 128]    \n","            elif output_np[i,j] == 8:  \n","                im_seg_RGB[i,j,:] = [64, 0, 128]    \n","            elif output_np[i,j] == 9:  \n","                im_seg_RGB[i,j,:] = [64, 64, 0]    \n","            elif output_np[i,j] == 10:  \n","                im_seg_RGB[i,j,:] = [0, 128, 192]    \n","                    \n","    # horizontally stack original image and its corresponding segmentation results     \n","    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n","    new_im = Image.fromarray(np.uint8(hstack_image))\n","    \n","    file_name = folder_to_save_validation_result + str(global_index) + '.jpg'\n","        \n","    global_index = global_index + 1\n","        \n","    new_im.save(file_name)     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7cK6h9vkbf7","colab_type":"code","colab":{}},"source":["# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n","# Calculates class intersections over unions\n","def iou(pred, target):\n","    ious = []\n","    for cls in range(num_class):\n","        pred_inds = pred == cls\n","        target_inds = target == cls\n","        intersection = pred_inds[target_inds].sum()\n","        union = pred_inds.sum() + target_inds.sum() - intersection\n","        if union == 0:\n","            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n","        else:\n","            ious.append(float(intersection) / max(union, 1))\n","        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\n","    return ious\n","\n","\n","def pixel_acc(pred, target):\n","    correct = (pred == target).sum()\n","    total   = (target == target).sum()\n","    return correct / total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrYQIIobkPZk","colab_type":"code","outputId":"19feba01-f5c1-46d3-ad17-d4bed3123796","executionInfo":{"status":"ok","timestamp":1576771690506,"user_tz":-480,"elapsed":480714,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## perform training and validation\n","val(0)  # show the accuracy before training\n","train()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["---------iter=0\n","epoch0, pix_acc: 0.03188079833984375, meanIoU: 0.0026567331949869794, IoUs: [0.        0.        0.        0.        0.        0.        0.\n"," 0.0318808 0.        0.        0.        0.       ]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["epoch0, iter0, loss: 0.6941513419151306\n","epoch0, iter10, loss: 0.5748529434204102\n","epoch0, iter20, loss: 0.42970696091651917\n","epoch0, iter30, loss: 0.34328407049179077\n","epoch0, iter40, loss: 0.30937284231185913\n","epoch0, iter50, loss: 0.284658819437027\n","epoch0, iter60, loss: 0.2899169921875\n","Finish epoch 0, time elapsed 45.65973234176636\n","---------iter=0\n","epoch0, pix_acc: 0.280057373046875, meanIoU: 0.03699695903525207, IoUs: [0.01511733 0.11441657 0.         0.28664062 0.00112133 0.\n"," 0.         0.01362534 0.01304232 0.         0.         0.        ]\n","epoch1, iter0, loss: 0.25996071100234985\n","epoch1, iter10, loss: 0.24954891204833984\n","epoch1, iter20, loss: 0.2309388369321823\n","epoch1, iter30, loss: 0.22469152510166168\n","epoch1, iter40, loss: 0.21673355996608734\n","epoch1, iter50, loss: 0.22815294563770294\n","epoch1, iter60, loss: 0.2300620675086975\n","Finish epoch 1, time elapsed 11.496820211410522\n","---------iter=0\n","epoch1, pix_acc: 0.45017822265625, meanIoU: 0.07473893196596494, IoUs: [2.78991853e-02 2.79828819e-01 0.00000000e+00 5.69106040e-01\n"," 0.00000000e+00 1.38352069e-02 0.00000000e+00 4.24364701e-04\n"," 5.77356806e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n","epoch2, iter0, loss: 0.21369798481464386\n","epoch2, iter10, loss: 0.20152132213115692\n","epoch2, iter20, loss: 0.19847935438156128\n","epoch2, iter30, loss: 0.18952706456184387\n","epoch2, iter40, loss: 0.17293302714824677\n","epoch2, iter50, loss: 0.1570117026567459\n","epoch2, iter60, loss: 0.16469818353652954\n","Finish epoch 2, time elapsed 11.51516342163086\n","---------iter=0\n","epoch2, pix_acc: 0.5579949951171875, meanIoU: 0.128630345200393, IoUs: [3.57048878e-01 3.55078916e-01 0.00000000e+00 8.08131089e-01\n"," 2.43348727e-03 5.33169304e-03 0.00000000e+00 0.00000000e+00\n"," 1.54222060e-02 0.00000000e+00 0.00000000e+00 1.17873637e-04]\n","epoch3, iter0, loss: 0.18507374823093414\n","epoch3, iter10, loss: 0.15647545456886292\n","epoch3, iter20, loss: 0.1804177314043045\n","epoch3, iter30, loss: 0.14775201678276062\n","epoch3, iter40, loss: 0.12626364827156067\n","epoch3, iter50, loss: 0.14357490837574005\n","epoch3, iter60, loss: 0.12556730210781097\n","Finish epoch 3, time elapsed 11.53269362449646\n","---------iter=0\n","epoch3, pix_acc: 0.6072175598144531, meanIoU: 0.1640610604874633, IoUs: [5.89738362e-01 4.12838492e-01 0.00000000e+00 8.14378446e-01\n"," 8.60699301e-02 4.84052986e-04 0.00000000e+00 8.29589561e-04\n"," 5.86861575e-02 0.00000000e+00 0.00000000e+00 5.70769571e-03]\n","epoch4, iter0, loss: 0.15440501272678375\n","epoch4, iter10, loss: 0.1190139427781105\n","epoch4, iter20, loss: 0.11964216828346252\n","epoch4, iter30, loss: 0.11376402527093887\n","epoch4, iter40, loss: 0.0936489924788475\n","epoch4, iter50, loss: 0.10151715576648712\n","epoch4, iter60, loss: 0.12992532551288605\n","Finish epoch 4, time elapsed 11.614463329315186\n","---------iter=0\n","epoch4, pix_acc: 0.6456282043457031, meanIoU: 0.19343558415751858, IoUs: [5.95069902e-01 5.20442609e-01 0.00000000e+00 8.46770646e-01\n"," 3.37533547e-03 2.87146692e-01 0.00000000e+00 1.01388848e-04\n"," 6.81555927e-02 0.00000000e+00 0.00000000e+00 1.64844554e-04]\n","epoch5, iter0, loss: 0.12699447572231293\n","epoch5, iter10, loss: 0.09729576855897903\n","epoch5, iter20, loss: 0.10838130116462708\n","epoch5, iter30, loss: 0.11307252943515778\n","epoch5, iter40, loss: 0.1311901956796646\n","epoch5, iter50, loss: 0.09533875435590744\n","epoch5, iter60, loss: 0.08413798362016678\n","Finish epoch 5, time elapsed 11.47363567352295\n","---------iter=0\n","epoch5, pix_acc: 0.715660400390625, meanIoU: 0.24825792140216266, IoUs: [7.78477929e-01 6.36532823e-01 0.00000000e+00 8.56136806e-01\n"," 4.68765528e-03 6.21456986e-01 0.00000000e+00 0.00000000e+00\n"," 8.11420093e-02 0.00000000e+00 0.00000000e+00 6.60848149e-04]\n","epoch6, iter0, loss: 0.10815701633691788\n","epoch6, iter10, loss: 0.0907648429274559\n","epoch6, iter20, loss: 0.11089968681335449\n","epoch6, iter30, loss: 0.07397916913032532\n","epoch6, iter40, loss: 0.07853291928768158\n","epoch6, iter50, loss: 0.08301755040884018\n","epoch6, iter60, loss: 0.08412545174360275\n","Finish epoch 6, time elapsed 11.563637018203735\n","---------iter=0\n","epoch6, pix_acc: 0.7412863159179688, meanIoU: 0.27713235335313396, IoUs: [0.8380652  0.69245932 0.         0.85497019 0.05894109 0.70351797\n"," 0.         0.00197529 0.11265218 0.         0.         0.06300699]\n","epoch7, iter0, loss: 0.0769699439406395\n","epoch7, iter10, loss: 0.08592649549245834\n","epoch7, iter20, loss: 0.10274430364370346\n","epoch7, iter30, loss: 0.09084967523813248\n","epoch7, iter40, loss: 0.07245709002017975\n","epoch7, iter50, loss: 0.08087889105081558\n","epoch7, iter60, loss: 0.1066909208893776\n","Finish epoch 7, time elapsed 11.553225994110107\n","---------iter=0\n","epoch7, pix_acc: 0.7623793029785156, meanIoU: 0.29368405105389944, IoUs: [8.67104474e-01 6.86285277e-01 2.42130751e-05 8.21860692e-01\n"," 1.57099538e-01 7.20476859e-01 0.00000000e+00 1.93729337e-03\n"," 1.66694993e-01 0.00000000e+00 0.00000000e+00 1.02725274e-01]\n","epoch8, iter0, loss: 0.09088213741779327\n","epoch8, iter10, loss: 0.11185227334499359\n","epoch8, iter20, loss: 0.08223598450422287\n","epoch8, iter30, loss: 0.09132066369056702\n","epoch8, iter40, loss: 0.07277598977088928\n","epoch8, iter50, loss: 0.07299388945102692\n","epoch8, iter60, loss: 0.10048005729913712\n","Finish epoch 8, time elapsed 11.552124500274658\n","---------iter=0\n","epoch8, pix_acc: 0.7741804504394532, meanIoU: 0.3056274489561378, IoUs: [0.84673372 0.69824976 0.         0.82646902 0.22368872 0.73063148\n"," 0.         0.00166074 0.21380076 0.         0.         0.12629518]\n","epoch9, iter0, loss: 0.08155903220176697\n","epoch9, iter10, loss: 0.06938082724809647\n","epoch9, iter20, loss: 0.06742990761995316\n","epoch9, iter30, loss: 0.06288792192935944\n","epoch9, iter40, loss: 0.10388251394033432\n","epoch9, iter50, loss: 0.08770330995321274\n","epoch9, iter60, loss: 0.10554914176464081\n","Finish epoch 9, time elapsed 11.598311185836792\n","---------iter=0\n","epoch9, pix_acc: 0.7947161865234375, meanIoU: 0.3343133586883474, IoUs: [0.85174117 0.69401765 0.         0.88246967 0.45434289 0.70500664\n"," 0.         0.00161799 0.30143946 0.         0.         0.12112485]\n","epoch10, iter0, loss: 0.08090444654226303\n","epoch10, iter10, loss: 0.08356107026338577\n","epoch10, iter20, loss: 0.06904963403940201\n","epoch10, iter30, loss: 0.07440084964036942\n","epoch10, iter40, loss: 0.0647791400551796\n","epoch10, iter50, loss: 0.08788590133190155\n","epoch10, iter60, loss: 0.07261606305837631\n","Finish epoch 10, time elapsed 11.599184274673462\n","---------iter=0\n","epoch10, pix_acc: 0.7941020202636718, meanIoU: 0.3412435093432647, IoUs: [8.60997674e-01 6.57764281e-01 3.96543398e-05 8.85511085e-01\n"," 5.43417522e-01 7.18936454e-01 0.00000000e+00 3.29279278e-03\n"," 3.04599859e-01 0.00000000e+00 0.00000000e+00 1.20362790e-01]\n","epoch11, iter0, loss: 0.0670829564332962\n","epoch11, iter10, loss: 0.07431716471910477\n","epoch11, iter20, loss: 0.06480655819177628\n","epoch11, iter30, loss: 0.05418481305241585\n","epoch11, iter40, loss: 0.08990726619958878\n","epoch11, iter50, loss: 0.05341934412717819\n","epoch11, iter60, loss: 0.07442724704742432\n","Finish epoch 11, time elapsed 11.634087800979614\n","---------iter=0\n","epoch11, pix_acc: 0.7944326782226563, meanIoU: 0.33999349745488155, IoUs: [0.88136545 0.67053915 0.         0.86793107 0.47925418 0.78062948\n"," 0.         0.0018507  0.2604759  0.         0.         0.13787604]\n","epoch12, iter0, loss: 0.08601987361907959\n","epoch12, iter10, loss: 0.07113831490278244\n","epoch12, iter20, loss: 0.07633062452077866\n","epoch12, iter30, loss: 0.05858824774622917\n","epoch12, iter40, loss: 0.06415196508169174\n","epoch12, iter50, loss: 0.059402067214250565\n","epoch12, iter60, loss: 0.06519947946071625\n","Finish epoch 12, time elapsed 11.642884492874146\n","---------iter=0\n","epoch12, pix_acc: 0.81515869140625, meanIoU: 0.36765785227772546, IoUs: [8.80574273e-01 7.07345908e-01 0.00000000e+00 8.92264549e-01\n"," 5.52246245e-01 7.79747350e-01 0.00000000e+00 4.25175231e-04\n"," 4.24759790e-01 0.00000000e+00 0.00000000e+00 1.74530937e-01]\n","epoch13, iter0, loss: 0.07408253103494644\n","epoch13, iter10, loss: 0.07766584306955338\n","epoch13, iter20, loss: 0.05893298611044884\n","epoch13, iter30, loss: 0.07496821880340576\n","epoch13, iter40, loss: 0.06279555708169937\n","epoch13, iter50, loss: 0.056752730160951614\n","epoch13, iter60, loss: 0.06043953448534012\n","Finish epoch 13, time elapsed 11.509988784790039\n","---------iter=0\n","epoch13, pix_acc: 0.8254972839355469, meanIoU: 0.3731725717366501, IoUs: [8.84772605e-01 7.08532456e-01 0.00000000e+00 9.13760760e-01\n"," 6.41372374e-01 8.06993580e-01 0.00000000e+00 2.68457340e-04\n"," 3.48860867e-01 0.00000000e+00 0.00000000e+00 1.73509762e-01]\n","epoch14, iter0, loss: 0.06611569970846176\n","epoch14, iter10, loss: 0.06793443113565445\n","epoch14, iter20, loss: 0.06533247977495193\n","epoch14, iter30, loss: 0.06236783042550087\n","epoch14, iter40, loss: 0.05649109557271004\n","epoch14, iter50, loss: 0.057241592556238174\n","epoch14, iter60, loss: 0.05844227597117424\n","Finish epoch 14, time elapsed 11.613168478012085\n","---------iter=0\n","epoch14, pix_acc: 0.8273001098632813, meanIoU: 0.37629016496266693, IoUs: [8.87323042e-01 7.11086136e-01 0.00000000e+00 9.09205399e-01\n"," 6.93980722e-01 8.31441061e-01 0.00000000e+00 4.59436431e-04\n"," 3.39716188e-01 0.00000000e+00 0.00000000e+00 1.42269996e-01]\n","epoch15, iter0, loss: 0.06725103408098221\n","epoch15, iter10, loss: 0.057272639125585556\n","epoch15, iter20, loss: 0.060385994613170624\n","epoch15, iter30, loss: 0.08155295252799988\n","epoch15, iter40, loss: 0.061522457748651505\n","epoch15, iter50, loss: 0.05740961804986\n","epoch15, iter60, loss: 0.05793088674545288\n","Finish epoch 15, time elapsed 11.52597951889038\n","---------iter=0\n","epoch15, pix_acc: 0.8157217407226562, meanIoU: 0.37249968909250736, IoUs: [8.78676212e-01 6.93463025e-01 0.00000000e+00 9.01371439e-01\n"," 5.40036279e-01 8.22885832e-01 0.00000000e+00 4.36421656e-05\n"," 4.63240043e-01 0.00000000e+00 0.00000000e+00 1.70279797e-01]\n","epoch16, iter0, loss: 0.06534955650568008\n","epoch16, iter10, loss: 0.045933160930871964\n","epoch16, iter20, loss: 0.07058731466531754\n","epoch16, iter30, loss: 0.06535742431879044\n","epoch16, iter40, loss: 0.05029765143990517\n","epoch16, iter50, loss: 0.0526757538318634\n","epoch16, iter60, loss: 0.045415133237838745\n","Finish epoch 16, time elapsed 11.517518758773804\n","---------iter=0\n","epoch16, pix_acc: 0.8345790100097656, meanIoU: 0.38168919795547507, IoUs: [0.88656718 0.71452654 0.         0.9114345  0.66527353 0.80418358\n"," 0.         0.         0.43637523 0.         0.         0.16190981]\n","epoch17, iter0, loss: 0.06218193843960762\n","epoch17, iter10, loss: 0.08060406148433685\n","epoch17, iter20, loss: 0.053508687764406204\n","epoch17, iter30, loss: 0.06021130830049515\n","epoch17, iter40, loss: 0.05535145103931427\n","epoch17, iter50, loss: 0.05052075535058975\n","epoch17, iter60, loss: 0.06884095817804337\n","Finish epoch 17, time elapsed 11.596647024154663\n","---------iter=0\n","epoch17, pix_acc: 0.8280111694335938, meanIoU: 0.38423542728622406, IoUs: [0.87450984 0.69947895 0.         0.9152913  0.63035617 0.82490093\n"," 0.         0.         0.50061376 0.         0.         0.16567418]\n","epoch18, iter0, loss: 0.0720473900437355\n","epoch18, iter10, loss: 0.04651788994669914\n","epoch18, iter20, loss: 0.06342526525259018\n","epoch18, iter30, loss: 0.05235937610268593\n","epoch18, iter40, loss: 0.05526009947061539\n","epoch18, iter50, loss: 0.051551733165979385\n","epoch18, iter60, loss: 0.06311709433794022\n","Finish epoch 18, time elapsed 11.569275140762329\n","---------iter=0\n","epoch18, pix_acc: 0.8170677185058594, meanIoU: 0.37107271682766313, IoUs: [8.57737827e-01 6.66234808e-01 0.00000000e+00 8.83649693e-01\n"," 6.52040496e-01 7.65054379e-01 0.00000000e+00 1.32418266e-03\n"," 4.26773148e-01 0.00000000e+00 2.99494603e-05 2.00028118e-01]\n","epoch19, iter0, loss: 0.07088066637516022\n","epoch19, iter10, loss: 0.06783052533864975\n","epoch19, iter20, loss: 0.06084328144788742\n","epoch19, iter30, loss: 0.051130473613739014\n","epoch19, iter40, loss: 0.060432784259319305\n","epoch19, iter50, loss: 0.07469386607408524\n","epoch19, iter60, loss: 0.05358578637242317\n","Finish epoch 19, time elapsed 11.5337393283844\n","---------iter=0\n","epoch19, pix_acc: 0.8261170959472657, meanIoU: 0.38126917398539467, IoUs: [8.77248171e-01 6.76161141e-01 0.00000000e+00 9.07918262e-01\n"," 6.46229944e-01 8.14291674e-01 0.00000000e+00 3.51639410e-04\n"," 4.67704813e-01 0.00000000e+00 5.82026793e-05 1.85266242e-01]\n","The highest mIOU is 0.38423542728622406 and is achieved at epoch-18\n","The highest pixel accuracy  is 0.8345790100097656 and is achieved at epoch-17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IbSvzMUrlGZU","colab_type":"code","outputId":"95a78d6e-c144-4f9b-9c6d-2e58f08f0267","executionInfo":{"status":"ok","timestamp":1576771690939,"user_tz":-480,"elapsed":481141,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["epoch = list(range(len(pixel_acc_list)))\n","plt.plot(epoch, pixel_acc_list, epoch, mIOU_list)\n","plt.legend(['pixel_acc', 'mIOU'])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fe1a66d4470>"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nITyEBLoQQngICXQhhPAQ/x84yCqlmx/5GgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}