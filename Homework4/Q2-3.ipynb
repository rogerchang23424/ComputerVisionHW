{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q2-3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6MlHCEAdZPy1","colab_type":"text"},"source":["**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n","So now you could mount your data to this ipynb!"]},{"cell_type":"code","metadata":{"id":"UGAXY5HMYjzL","colab_type":"code","outputId":"a57a11cb-fd7f-4880-9e2e-d9f39031b960","executionInfo":{"status":"ok","timestamp":1579673909717,"user_tz":-480,"elapsed":1194,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wTBYCMcpZoA8","colab_type":"code","outputId":"5352b271-17d6-405e-c6c9-e0fcead35421","executionInfo":{"status":"ok","timestamp":1579673912825,"user_tz":-480,"elapsed":4294,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# if you mount Google drive correctly, the following commands should be able to executed correctly\n","!ls /content/drive/\n","%cd \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/\"\n","%cd \"CamVid\"\n","\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'My Drive'\n","/content/drive/My Drive/Colab Notebooks/HW4_updated1\n","/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid\n","result_comparision  trainannot\ttrain.gsheet  valannot\n","train\t\t    train.csv\tval\t      val.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfWmPZKyZ8gA","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import utils\n","import torchvision\n","from torchvision import models\n","from torchvision.models.vgg import VGG\n","import random\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import time\n","import sys\n","import os\n","from os import path\n","\n","from PIL import Image\n","import pandas as pd\n","from torchvision.models.vgg import VGG\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxRR6L-k3Hjq","colab_type":"code","colab":{}},"source":["seed = 1450\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMzL2KhcaI9u","colab_type":"code","outputId":"13de3885-9b03-4052-9b4c-f8d9105c224d","executionInfo":{"status":"ok","timestamp":1579673913455,"user_tz":-480,"elapsed":4907,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","root_dir   = \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/\"\n","train_file = os.path.join(root_dir, \"train.csv\")\n","val_file   = os.path.join(root_dir, \"val.csv\")\n","\n","print(\"training csv exits:{}\".format(path.exists(train_file)))\n","print(\"validation csv exits:{}\".format(path.exists(val_file)))\n","\n","# the folder to save results for comparison\n","folder_to_save_validation_result = '/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/result_comparision/' \n","\n","if os.path.isdir(folder_to_save_validation_result) == False:\n","    os.mkdir(folder_to_save_validation_result)\n","\n","\n","# the number of segmentation classes\n","num_class = 3 # 32 for original CamVid\n","means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n","\n","h, w      = 256, 256\n","train_h = 256\n","train_w = 256\n","val_h = 256\n","val_w = 256\n","\n","## parameters for Solver-Adam in this example\n","batch_size = 6 #\n","epochs     = 50 # don't try to improve the performance by simply increasing the training epochs or iterations\n","lr         = 1e-4    # achieved besty results \n","step_size  = 100 # Won't work when epochs <=100\n","gamma      = 0.5 # \n","#\n","\n","## index for validation images\n","global_index = 0\n","\n","# pixel accuracy and mIOU list \n","pixel_acc_list = []\n","mIOU_list = []\n","\n","use_gpu = torch.cuda.is_available()\n","num_gpu = list(range(torch.cuda.device_count()))\n","\n","class CamVidDataset(Dataset):\n","\n","    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n","        self.data      = pd.read_csv(csv_file)\n","        self.means     = means\n","        self.n_class   = n_class\n","        self.flip_rate = flip_rate       \n","\n","        self.resize_h = h\n","        self.resize_w = w        \n","        \n","        if phase == 'train':\n","            self.new_h = train_h\n","            self.new_w = train_w\n","            self.crop = crop\n","        elif phase == 'val':\n","            self.flip_rate = 0.\n","            self.crop = False # False\n","            self.new_h = val_h\n","            self.new_w = val_w\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_name   = self.data.iloc[idx, 0]                \n","        img_name = root_dir  + img_name                        \n","        img = Image.open(img_name).convert('RGB')  \n","\n","        label_name = self.data.iloc[idx, 1]        \n","        label_name = root_dir  + label_name                       \n","        label_image = Image.open(label_name)\n","        label = np.asarray(label_image)\n","\n","        # In training mode, the crop strategy is random-shift crop.\n","        # In validation model, it is center crop.\n","        if self.crop:            \n","            w, h = img.size\n","            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n","            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n","\n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","        else:            \n","            w, h = img.size\n","            A_x_offset = int((w - self.new_w)/2)\n","            A_y_offset = int((h - self.new_h)/2)\n","            \n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","\n","            label_image_h, label_image_w = label_image.size\n","\n","        # we could try to revise the values in label for reducing the number of segmentation classes\n","        label = np.array(label_image)\n","        label[label == 2] = 1\n","        label[label == 3] = 1\n","        label[label == 4] = 1\n","        label[label == 5] = 1\n","        label[label == 6] = 1\n","        label[label == 7] = 1\n","        label[label == 8] = 2\n","        label[label == 9] = 2\n","        label[label == 10] = 2\n","\n","        if random.random() < self.flip_rate:\n","            img   = np.fliplr(img)\n","            label = np.fliplr(label)\n","        \n","        # reduce mean in terms of BGR\n","        img = np.transpose(img, (2, 0, 1)) / 255.\n","        img[0] -= self.means[0]\n","        img[1] -= self.means[1]\n","        img[2] -= self.means[2]\n","\n","        # convert to tensor\n","        img = torch.from_numpy(img.copy()).float()\n","        label = torch.from_numpy(label.copy()).long()\n","\n","        # create one-hot encoding\n","        h, w = label.size()\n","        target = torch.zeros(self.n_class, h, w)\n","        for c in range(self.n_class):\n","            target[c][label == c] = 1\n","\n","        sample = {'X': img, 'Y': target, 'l': label}\n","\n","        return sample\n","\n","\n","train_data = CamVidDataset(csv_file=train_file, phase='train')\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n","\n","val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n","val_loader = DataLoader(val_data, batch_size=1, num_workers=8)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["training csv exits:True\n","validation csv exits:True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4h-a5moWhLhF","colab_type":"code","colab":{}},"source":["# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n","cfg = {\n","    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","ranges = {\n","    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n","    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n","    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n","    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n","}\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)\n","\n","class VGGNet(VGG):\n","    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n","        super().__init__(make_layers(cfg[model]))\n","        self.ranges = ranges[model]\n","\n","        if pretrained:            \n","            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n","\n","        if not requires_grad:\n","            for param in super().parameters():\n","                param.requires_grad = False\n","\n","        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n","            del self.classifier\n","\n","        if show_params:\n","            for name, param in self.named_parameters():\n","                print(name, param.size())\n","\n","    def forward(self, x):\n","        output = {}\n","\n","        # get the output of each maxpooling layer (5 maxpool in VGG net)\n","        for idx in range(len(self.ranges)):\n","            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n","                x = self.features[layer](x)\n","            output[\"x%d\"%(idx+1)] = x\n","\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZWlA75uj4u1","colab_type":"code","colab":{}},"source":["class FCN8s(nn.Module):\n","    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n","    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu    = nn.ReLU(inplace=True)\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn1     = nn.BatchNorm2d(512)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn2     = nn.BatchNorm2d(256)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn3     = nn.BatchNorm2d(128)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn4     = nn.BatchNorm2d(64)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn5     = nn.BatchNorm2d(32)\n","        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.pretrained_net(x)\n","        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n","        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n","        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n","\n","        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n","        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n","        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n","        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n","        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n","        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n","        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n","        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n","\n","        return score  # size=(N, n_class, x.H/1, x.W/1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_d5x1O2j53K","colab_type":"code","outputId":"10905ebb-25c4-430d-b760-cb160412ec4b","executionInfo":{"status":"ok","timestamp":1579673920323,"user_tz":-480,"elapsed":11758,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["# load pretrained weights and define FCN8s\n","vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n","fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n","\n","ts = time.time()\n","vgg_model = vgg_model.cuda()\n","fcn_model = fcn_model.cuda()\n","fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n","print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=11)\n","optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","print(fcn_model)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Finish cuda loading, time elapsed 3.4392104148864746\n","DataParallel(\n","  (module): FCN8s(\n","    (pretrained_net): VGGNet(\n","      (features): Sequential(\n","        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): ReLU(inplace=True)\n","        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (6): ReLU(inplace=True)\n","        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (8): ReLU(inplace=True)\n","        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (11): ReLU(inplace=True)\n","        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (13): ReLU(inplace=True)\n","        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (15): ReLU(inplace=True)\n","        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (18): ReLU(inplace=True)\n","        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (20): ReLU(inplace=True)\n","        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (22): ReLU(inplace=True)\n","        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (25): ReLU(inplace=True)\n","        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (27): ReLU(inplace=True)\n","        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (29): ReLU(inplace=True)\n","        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    )\n","    (relu): ReLU(inplace=True)\n","    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (classifier): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"scngbKimJU0P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oExd6u7kkLw6","colab_type":"code","colab":{}},"source":["def val(epoch):\n","    fcn_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","                    \n","    \n","    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n","        if use_gpu:\n","            inputs = Variable(batch['X'].cuda())\n","        else:\n","            inputs = Variable(batch['X'])        \n","\n","        output = fcn_model(inputs)                                \n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            print('---------iter={}'.format(iter))\n","            # generate images\n","            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n","            image = images[0,:,:]        \n","            save_result_comparison(batch['X'], image)\n","                            \n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape                \n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n","        target = batch['l'].cpu().numpy().reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t, num_class))\n","            pixel_accs.append(pixel_acc(p, t, num_class))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n","    \n","    global pixel_acc_list\n","    global mIOU_list\n","    \n","    pixel_acc_list.append(pixel_accs)\n","    mIOU_list.append(np.nanmean(ious))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUjPeffKbm36","colab_type":"code","colab":{}},"source":["def train():\n","    for epoch in range(epochs):\n","        scheduler.step()\n","\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","\n","            if use_gpu:\n","                inputs = Variable(batch['X'].cuda())\n","                labels = Variable(batch['l'].cuda())\n","            else:\n","                inputs, labels = Variable(batch['X']), Variable(batch['l'])\n","\n","            outputs = fcn_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n","        \n","\n","        val(epoch)\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)        \n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qj9aXgiYkYfW","colab_type":"code","colab":{}},"source":["def save_result_comparison(input_np, output_np):\n","    means     = np.array([103.939, 116.779, 123.68]) / 255.\n","    \n","    global global_index\n","    \n","    original_im_RGB = np.zeros((256,256,3))    \n","    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n","    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n","    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n","    \n","    im_seg_RGB = np.zeros((256,256,3))\n","\n","    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n","    for i in range(256):\n","        for j in range(256):\n","            if output_np[i,j] == 0:\n","                im_seg_RGB[i,j,:] = [128, 128, 128]\n","            elif output_np[i,j] == 1:  \n","                im_seg_RGB[i,j,:] = [0, 0, 0]\n","            elif output_np[i,j] == 2:  \n","                im_seg_RGB[i,j,:] = [0, 128, 192]      \n","                    \n","    # horizontally stack original image and its corresponding segmentation results     \n","    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n","    new_im = Image.fromarray(np.uint8(hstack_image))\n","    \n","    file_name = folder_to_save_validation_result + str(global_index) + '.jpg'\n","        \n","    global_index = global_index + 1\n","        \n","    new_im.save(file_name)     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7cK6h9vkbf7","colab_type":"code","colab":{}},"source":["# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n","# Calculates class intersections over unions\n","def fast_hist(pred, target, num_class):\n","    mask = (target >= 0) & (target < num_class)\n","    return np.bincount(num_class * target[mask] + pred[mask], minlength=num_class ** 2).reshape(num_class, num_class)\n","\n","def iou(pred, target, num_class):\n","    hist = fast_hist(pred, target, num_class)\n","    ious = []\n","    for i in range(num_class):\n","        calc = float(hist[i, :].sum() + hist[:, i].sum() - hist[i, i])\n","        if calc == 0:\n","            ious.append(float(\"nan\"))\n","        else:\n","            ious.append(float(hist[i, i]) / calc)\n","    return ious\n","\n","def pixel_acc(pred, target, num_class):\n","    hist = fast_hist(pred, target, num_class)\n","    return np.diag(hist).sum() / hist.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrYQIIobkPZk","colab_type":"code","outputId":"5df2bb61-debc-4576-8706-f8b01004fc00","executionInfo":{"status":"ok","timestamp":1579674885570,"user_tz":-480,"elapsed":976970,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## perform training and validation\n","val(0)  # show the accuracy before training\n","train()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["---------iter=0\n","epoch0, pix_acc: 0.822712254594056, meanIoU: 0.2742374181980187, IoUs: [0.         0.82271225 0.        ]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["epoch0, iter0, loss: 0.9801363348960876\n","epoch0, iter10, loss: 0.44616445899009705\n","epoch0, iter20, loss: 0.6963747143745422\n","epoch0, iter30, loss: 0.5485827326774597\n","epoch0, iter40, loss: 0.49877530336380005\n","epoch0, iter50, loss: 0.35863158106803894\n","epoch0, iter60, loss: 0.47226619720458984\n","Finish epoch 0, time elapsed 15.741577386856079\n","---------iter=0\n","epoch0, pix_acc: 0.8227125655925466, meanIoU: 0.2742383352055732, IoUs: [2.50367027e-06 8.22712502e-01 0.00000000e+00]\n","epoch1, iter0, loss: 0.4118587076663971\n","epoch1, iter10, loss: 0.5834832787513733\n","epoch1, iter20, loss: 0.3063526153564453\n","epoch1, iter30, loss: 0.29885947704315186\n","epoch1, iter40, loss: 0.22261759638786316\n","epoch1, iter50, loss: 0.18708916008472443\n","epoch1, iter60, loss: 0.23249128460884094\n","Finish epoch 1, time elapsed 16.075050354003906\n","---------iter=0\n","epoch1, pix_acc: 0.9323574425737475, meanIoU: 0.6639555943855034, IoUs: [0.90041277 0.92294083 0.16851318]\n","epoch2, iter0, loss: 0.16819484531879425\n","epoch2, iter10, loss: 0.13885433971881866\n","epoch2, iter20, loss: 0.09856456518173218\n","epoch2, iter30, loss: 0.15924698114395142\n","epoch2, iter40, loss: 0.14707636833190918\n","epoch2, iter50, loss: 0.12211082875728607\n","epoch2, iter60, loss: 0.14629091322422028\n","Finish epoch 2, time elapsed 16.35934567451477\n","---------iter=0\n","epoch2, pix_acc: 0.9545436820729875, meanIoU: 0.796355297425103, IoUs: [0.90909322 0.94611703 0.53385564]\n","epoch3, iter0, loss: 0.14320982992649078\n","epoch3, iter10, loss: 0.15877123177051544\n","epoch3, iter20, loss: 0.12328508496284485\n","epoch3, iter30, loss: 0.1376911997795105\n","epoch3, iter40, loss: 0.14686518907546997\n","epoch3, iter50, loss: 0.09954053908586502\n","epoch3, iter60, loss: 0.127572700381279\n","Finish epoch 3, time elapsed 16.23571228981018\n","---------iter=0\n","epoch3, pix_acc: 0.9544480733822774, meanIoU: 0.8042630522622131, IoUs: [0.88180726 0.94558788 0.58539401]\n","epoch4, iter0, loss: 0.11917231231927872\n","epoch4, iter10, loss: 0.208465114235878\n","epoch4, iter20, loss: 0.14254507422447205\n","epoch4, iter30, loss: 0.09578511863946915\n","epoch4, iter40, loss: 0.06240997090935707\n","epoch4, iter50, loss: 0.09561777859926224\n","epoch4, iter60, loss: 0.10815698653459549\n","Finish epoch 4, time elapsed 16.02600336074829\n","---------iter=0\n","epoch4, pix_acc: 0.963722319781462, meanIoU: 0.8444375849539137, IoUs: [0.91874087 0.9564072  0.65816469]\n","epoch5, iter0, loss: 0.1615760773420334\n","epoch5, iter10, loss: 0.12983836233615875\n","epoch5, iter20, loss: 0.12172114104032516\n","epoch5, iter30, loss: 0.06715046614408493\n","epoch5, iter40, loss: 0.07653595507144928\n","epoch5, iter50, loss: 0.08849678188562393\n","epoch5, iter60, loss: 0.06717924028635025\n","Finish epoch 5, time elapsed 15.940129518508911\n","---------iter=0\n","epoch5, pix_acc: 0.9651776595318513, meanIoU: 0.8424088845507794, IoUs: [0.92150956 0.95826352 0.64745357]\n","epoch6, iter0, loss: 0.14318646490573883\n","epoch6, iter10, loss: 0.07773452997207642\n","epoch6, iter20, loss: 0.06535180658102036\n","epoch6, iter30, loss: 0.08833285421133041\n","epoch6, iter40, loss: 0.06579558551311493\n","epoch6, iter50, loss: 0.08185064792633057\n","epoch6, iter60, loss: 0.10289205610752106\n","Finish epoch 6, time elapsed 16.187727451324463\n","---------iter=0\n","epoch6, pix_acc: 0.9682104047793539, meanIoU: 0.846170159607501, IoUs: [0.9214348  0.96206281 0.65501287]\n","epoch7, iter0, loss: 0.12460723519325256\n","epoch7, iter10, loss: 0.09518474340438843\n","epoch7, iter20, loss: 0.17275309562683105\n","epoch7, iter30, loss: 0.09833487123250961\n","epoch7, iter40, loss: 0.13118579983711243\n","epoch7, iter50, loss: 0.0766998901963234\n","epoch7, iter60, loss: 0.17111560702323914\n","Finish epoch 7, time elapsed 16.365124940872192\n","---------iter=0\n","epoch7, pix_acc: 0.9580469199436612, meanIoU: 0.7831885606760459, IoUs: [0.92222359 0.95093693 0.47640516]\n","epoch8, iter0, loss: 0.09121095389127731\n","epoch8, iter10, loss: 0.12092264741659164\n","epoch8, iter20, loss: 0.12325908243656158\n","epoch8, iter30, loss: 0.0819954201579094\n","epoch8, iter40, loss: 0.045081254094839096\n","epoch8, iter50, loss: 0.07228218764066696\n","epoch8, iter60, loss: 0.12951882183551788\n","Finish epoch 8, time elapsed 16.181880712509155\n","---------iter=0\n","epoch8, pix_acc: 0.9719486302287932, meanIoU: 0.8750068962201684, IoUs: [0.92173616 0.96618714 0.73709739]\n","epoch9, iter0, loss: 0.09470293670892715\n","epoch9, iter10, loss: 0.051453858613967896\n","epoch9, iter20, loss: 0.08931906521320343\n","epoch9, iter30, loss: 0.07906346023082733\n","epoch9, iter40, loss: 0.09050312638282776\n","epoch9, iter50, loss: 0.07003077864646912\n","epoch9, iter60, loss: 0.09561941027641296\n","Finish epoch 9, time elapsed 16.270031213760376\n","---------iter=0\n","epoch9, pix_acc: 0.9713213538831112, meanIoU: 0.8725890253315235, IoUs: [0.91675312 0.96540032 0.73561363]\n","epoch10, iter0, loss: 0.07266414910554886\n","epoch10, iter10, loss: 0.06573977321386337\n","epoch10, iter20, loss: 0.06570304185152054\n","epoch10, iter30, loss: 0.10847757756710052\n","epoch10, iter40, loss: 0.090303935110569\n","epoch10, iter50, loss: 0.05011594295501709\n","epoch10, iter60, loss: 0.05351613461971283\n","Finish epoch 10, time elapsed 16.262757062911987\n","---------iter=0\n","epoch10, pix_acc: 0.9705118132466677, meanIoU: 0.8725079943921997, IoUs: [0.91969986 0.96432553 0.73349859]\n","epoch11, iter0, loss: 0.08918073773384094\n","epoch11, iter10, loss: 0.07289986312389374\n","epoch11, iter20, loss: 0.09444937109947205\n","epoch11, iter30, loss: 0.06822936236858368\n","epoch11, iter40, loss: 0.05676872655749321\n","epoch11, iter50, loss: 0.07833738625049591\n","epoch11, iter60, loss: 0.06887593120336533\n","Finish epoch 11, time elapsed 16.09038734436035\n","---------iter=0\n","epoch11, pix_acc: 0.9732155003297447, meanIoU: 0.878485935963421, IoUs: [0.92493842 0.96780022 0.74271916]\n","epoch12, iter0, loss: 0.09300244599580765\n","epoch12, iter10, loss: 0.07046417146921158\n","epoch12, iter20, loss: 0.08212102949619293\n","epoch12, iter30, loss: 0.10238721966743469\n","epoch12, iter40, loss: 0.06122405827045441\n","epoch12, iter50, loss: 0.06672409176826477\n","epoch12, iter60, loss: 0.08097802102565765\n","Finish epoch 12, time elapsed 16.12047266960144\n","---------iter=0\n","epoch12, pix_acc: 0.9725658812309044, meanIoU: 0.876197821592999, IoUs: [0.92498294 0.96691811 0.73669241]\n","epoch13, iter0, loss: 0.09946099668741226\n","epoch13, iter10, loss: 0.0807303860783577\n","epoch13, iter20, loss: 0.08301431685686111\n","epoch13, iter30, loss: 0.06507536768913269\n","epoch13, iter40, loss: 0.07624229043722153\n","epoch13, iter50, loss: 0.050384338945150375\n","epoch13, iter60, loss: 0.09196306765079498\n","Finish epoch 13, time elapsed 16.28077459335327\n","---------iter=0\n","epoch13, pix_acc: 0.9675718812817782, meanIoU: 0.835219795457721, IoUs: [0.9253512  0.96153316 0.61877503]\n","epoch14, iter0, loss: 0.06107306107878685\n","epoch14, iter10, loss: 0.09643926471471786\n","epoch14, iter20, loss: 0.07300136238336563\n","epoch14, iter30, loss: 0.08703576028347015\n","epoch14, iter40, loss: 0.07896921038627625\n","epoch14, iter50, loss: 0.07916264235973358\n","epoch14, iter60, loss: 0.07548984885215759\n","Finish epoch 14, time elapsed 16.23765516281128\n","---------iter=0\n","epoch14, pix_acc: 0.9632930474274716, meanIoU: 0.8496337920709887, IoUs: [0.9249306  0.95567077 0.6683    ]\n","epoch15, iter0, loss: 0.09268856793642044\n","epoch15, iter10, loss: 0.07806916534900665\n","epoch15, iter20, loss: 0.09463207423686981\n","epoch15, iter30, loss: 0.06808412820100784\n","epoch15, iter40, loss: 0.07733487337827682\n","epoch15, iter50, loss: 0.06866142898797989\n","epoch15, iter60, loss: 0.06957308202981949\n","Finish epoch 15, time elapsed 16.1948664188385\n","---------iter=0\n","epoch15, pix_acc: 0.9740797450872699, meanIoU: 0.8822838543729979, IoUs: [0.92679299 0.96878056 0.75127802]\n","epoch16, iter0, loss: 0.06828255206346512\n","epoch16, iter10, loss: 0.057547759264707565\n","epoch16, iter20, loss: 0.07543673366308212\n","epoch16, iter30, loss: 0.08993376791477203\n","epoch16, iter40, loss: 0.06702405959367752\n","epoch16, iter50, loss: 0.06360124051570892\n","epoch16, iter60, loss: 0.07441643625497818\n","Finish epoch 16, time elapsed 16.225564002990723\n","---------iter=0\n","epoch16, pix_acc: 0.9727157782010177, meanIoU: 0.8761503932735203, IoUs: [0.91070272 0.96715798 0.75059048]\n","epoch17, iter0, loss: 0.12727653980255127\n","epoch17, iter10, loss: 0.07707631587982178\n","epoch17, iter20, loss: 0.06701558083295822\n","epoch17, iter30, loss: 0.05255178362131119\n","epoch17, iter40, loss: 0.05139452591538429\n","epoch17, iter50, loss: 0.05533168464899063\n","epoch17, iter60, loss: 0.08071617782115936\n","Finish epoch 17, time elapsed 16.215087890625\n","---------iter=0\n","epoch17, pix_acc: 0.9747703550988546, meanIoU: 0.8879674991143024, IoUs: [0.92716776 0.96949882 0.76723591]\n","epoch18, iter0, loss: 0.06755847483873367\n","epoch18, iter10, loss: 0.06158725917339325\n","epoch18, iter20, loss: 0.07044881582260132\n","epoch18, iter30, loss: 0.11105024814605713\n","epoch18, iter40, loss: 0.09204855561256409\n","epoch18, iter50, loss: 0.09408998489379883\n","epoch18, iter60, loss: 0.09751981496810913\n","Finish epoch 18, time elapsed 16.27791976928711\n","---------iter=0\n","epoch18, pix_acc: 0.9728788418216867, meanIoU: 0.8793947084602375, IoUs: [0.92271492 0.96724531 0.7482239 ]\n","epoch19, iter0, loss: 0.10541287064552307\n","epoch19, iter10, loss: 0.10426031053066254\n","epoch19, iter20, loss: 0.0604015588760376\n","epoch19, iter30, loss: 0.060416195541620255\n","epoch19, iter40, loss: 0.08005335927009583\n","epoch19, iter50, loss: 0.08082810044288635\n","epoch19, iter60, loss: 0.07115256041288376\n","Finish epoch 19, time elapsed 16.100254774093628\n","---------iter=0\n","epoch19, pix_acc: 0.9731149306021969, meanIoU: 0.8746880362906241, IoUs: [0.9281435  0.96758535 0.72833527]\n","epoch20, iter0, loss: 0.10157088935375214\n","epoch20, iter10, loss: 0.041461534798145294\n","epoch20, iter20, loss: 0.06346488744020462\n","epoch20, iter30, loss: 0.07127396762371063\n","epoch20, iter40, loss: 0.06384150683879852\n","epoch20, iter50, loss: 0.03787421062588692\n","epoch20, iter60, loss: 0.07242933660745621\n","Finish epoch 20, time elapsed 16.19199252128601\n","---------iter=0\n","epoch20, pix_acc: 0.9752133686103568, meanIoU: 0.8800430374723307, IoUs: [0.92761814 0.97021223 0.74229873]\n","epoch21, iter0, loss: 0.05650421604514122\n","epoch21, iter10, loss: 0.06172094866633415\n","epoch21, iter20, loss: 0.08240558952093124\n","epoch21, iter30, loss: 0.09478472918272018\n","epoch21, iter40, loss: 0.09632036089897156\n","epoch21, iter50, loss: 0.07865288108587265\n","epoch21, iter60, loss: 0.05937318131327629\n","Finish epoch 21, time elapsed 16.135645866394043\n","---------iter=0\n","epoch21, pix_acc: 0.9729625717033591, meanIoU: 0.877112954601357, IoUs: [0.92801243 0.96732754 0.73599889]\n","epoch22, iter0, loss: 0.06077601760625839\n","epoch22, iter10, loss: 0.06079579517245293\n","epoch22, iter20, loss: 0.06217721849679947\n","epoch22, iter30, loss: 0.06153770163655281\n","epoch22, iter40, loss: 0.05918586999177933\n","epoch22, iter50, loss: 0.04548761248588562\n","epoch22, iter60, loss: 0.05773679167032242\n","Finish epoch 22, time elapsed 16.15701937675476\n","---------iter=0\n","epoch22, pix_acc: 0.9754857445286044, meanIoU: 0.8837733252333436, IoUs: [0.92881832 0.97052809 0.75197356]\n","epoch23, iter0, loss: 0.06825950741767883\n","epoch23, iter10, loss: 0.07590591907501221\n","epoch23, iter20, loss: 0.07367682456970215\n","epoch23, iter30, loss: 0.060745108872652054\n","epoch23, iter40, loss: 0.04462171718478203\n","epoch23, iter50, loss: 0.05410955473780632\n","epoch23, iter60, loss: 0.05061707645654678\n","Finish epoch 23, time elapsed 16.17869234085083\n","---------iter=0\n","epoch23, pix_acc: 0.9754357439610404, meanIoU: 0.8836566933606634, IoUs: [0.92774887 0.97046411 0.75275709]\n","epoch24, iter0, loss: 0.05199354514479637\n","epoch24, iter10, loss: 0.049057118594646454\n","epoch24, iter20, loss: 0.04129309579730034\n","epoch24, iter30, loss: 0.07672400027513504\n","epoch24, iter40, loss: 0.0803123414516449\n","epoch24, iter50, loss: 0.04529961198568344\n","epoch24, iter60, loss: 0.048843204975128174\n","Finish epoch 24, time elapsed 16.188685655593872\n","---------iter=0\n","epoch24, pix_acc: 0.9743488328277294, meanIoU: 0.877162101241864, IoUs: [0.92901376 0.96911825 0.7333543 ]\n","epoch25, iter0, loss: 0.06364583969116211\n","epoch25, iter10, loss: 0.04763124883174896\n","epoch25, iter20, loss: 0.05035528913140297\n","epoch25, iter30, loss: 0.05224372446537018\n","epoch25, iter40, loss: 0.04390280693769455\n","epoch25, iter50, loss: 0.04881119355559349\n","epoch25, iter60, loss: 0.045888591557741165\n","Finish epoch 25, time elapsed 16.265758752822876\n","---------iter=0\n","epoch25, pix_acc: 0.9749332852767527, meanIoU: 0.8763913980339796, IoUs: [0.92605279 0.96992668 0.73319473]\n","epoch26, iter0, loss: 0.05960719287395477\n","epoch26, iter10, loss: 0.05329892411828041\n","epoch26, iter20, loss: 0.052811719477176666\n","epoch26, iter30, loss: 0.0635046660900116\n","epoch26, iter40, loss: 0.09144539386034012\n","epoch26, iter50, loss: 0.059230927377939224\n","epoch26, iter60, loss: 0.045878201723098755\n","Finish epoch 26, time elapsed 16.23224449157715\n","---------iter=0\n","epoch26, pix_acc: 0.9770429803183227, meanIoU: 0.8888472339212776, IoUs: [0.92874134 0.97243765 0.76536271]\n","epoch27, iter0, loss: 0.0508810356259346\n","epoch27, iter10, loss: 0.07912138849496841\n","epoch27, iter20, loss: 0.06880469620227814\n","epoch27, iter30, loss: 0.06717123836278915\n","epoch27, iter40, loss: 0.0454961434006691\n","epoch27, iter50, loss: 0.04801509156823158\n","epoch27, iter60, loss: 0.14441977441310883\n","Finish epoch 27, time elapsed 16.16449737548828\n","---------iter=0\n","epoch27, pix_acc: 0.9738759657383739, meanIoU: 0.8798234500169549, IoUs: [0.92746068 0.96849706 0.74351261]\n","epoch28, iter0, loss: 0.05611531808972359\n","epoch28, iter10, loss: 0.07796778529882431\n","epoch28, iter20, loss: 0.07930884510278702\n","epoch28, iter30, loss: 0.052823230624198914\n","epoch28, iter40, loss: 0.051131121814250946\n","epoch28, iter50, loss: 0.0464736633002758\n","epoch28, iter60, loss: 0.04253973811864853\n","Finish epoch 28, time elapsed 16.229365348815918\n","---------iter=0\n","epoch28, pix_acc: 0.9756876459256009, meanIoU: 0.8795807474091052, IoUs: [0.92758111 0.97078613 0.74037501]\n","epoch29, iter0, loss: 0.04544922709465027\n","epoch29, iter10, loss: 0.0568402037024498\n","epoch29, iter20, loss: 0.09532632678747177\n","epoch29, iter30, loss: 0.06703212112188339\n","epoch29, iter40, loss: 0.05238364636898041\n","epoch29, iter50, loss: 0.05228058621287346\n","epoch29, iter60, loss: 0.030000504106283188\n","Finish epoch 29, time elapsed 16.17738437652588\n","---------iter=0\n","epoch29, pix_acc: 0.9765146599916068, meanIoU: 0.8867644491357475, IoUs: [0.92817441 0.97169926 0.76041968]\n","epoch30, iter0, loss: 0.05534439533948898\n","epoch30, iter10, loss: 0.05416588485240936\n","epoch30, iter20, loss: 0.06757335364818573\n","epoch30, iter30, loss: 0.05821729451417923\n","epoch30, iter40, loss: 0.09672872722148895\n","epoch30, iter50, loss: 0.03436164930462837\n","epoch30, iter60, loss: 0.057522937655448914\n","Finish epoch 30, time elapsed 16.248616218566895\n","---------iter=0\n","epoch30, pix_acc: 0.9755157945725865, meanIoU: 0.886049877984719, IoUs: [0.91796692 0.97044631 0.7697364 ]\n","epoch31, iter0, loss: 0.06507200002670288\n","epoch31, iter10, loss: 0.039445921778678894\n","epoch31, iter20, loss: 0.08248573541641235\n","epoch31, iter30, loss: 0.04325050860643387\n","epoch31, iter40, loss: 0.04013003781437874\n","epoch31, iter50, loss: 0.07964757084846497\n","epoch31, iter60, loss: 0.05720546841621399\n","Finish epoch 31, time elapsed 16.231688976287842\n","---------iter=0\n","epoch31, pix_acc: 0.9757012176517117, meanIoU: 0.8841506862247455, IoUs: [0.92741857 0.97072043 0.75431306]\n","epoch32, iter0, loss: 0.0655706375837326\n","epoch32, iter10, loss: 0.05470755696296692\n","epoch32, iter20, loss: 0.06768929958343506\n","epoch32, iter30, loss: 0.052635278552770615\n","epoch32, iter40, loss: 0.04982350021600723\n","epoch32, iter50, loss: 0.039455804973840714\n","epoch32, iter60, loss: 0.04781169816851616\n","Finish epoch 32, time elapsed 16.215354442596436\n","---------iter=0\n","epoch32, pix_acc: 0.9758145537038252, meanIoU: 0.887062955425848, IoUs: [0.92233946 0.97080515 0.76804426]\n","epoch33, iter0, loss: 0.06423472613096237\n","epoch33, iter10, loss: 0.05824939161539078\n","epoch33, iter20, loss: 0.0655347928404808\n","epoch33, iter30, loss: 0.08927960693836212\n","epoch33, iter40, loss: 0.06155456602573395\n","epoch33, iter50, loss: 0.049401767551898956\n","epoch33, iter60, loss: 0.06257078051567078\n","Finish epoch 33, time elapsed 16.219821214675903\n","---------iter=0\n","epoch33, pix_acc: 0.9745309496359503, meanIoU: 0.8871729078433189, IoUs: [0.92355106 0.96919508 0.76877258]\n","epoch34, iter0, loss: 0.058352526277303696\n","epoch34, iter10, loss: 0.06282136589288712\n","epoch34, iter20, loss: 0.06023690849542618\n","epoch34, iter30, loss: 0.05298841744661331\n","epoch34, iter40, loss: 0.04547293484210968\n","epoch34, iter50, loss: 0.036995213478803635\n","epoch34, iter60, loss: 0.0733552798628807\n","Finish epoch 34, time elapsed 16.16204261779785\n","---------iter=0\n","epoch34, pix_acc: 0.9764371232370498, meanIoU: 0.889083235752107, IoUs: [0.92663699 0.971613   0.76899971]\n","epoch35, iter0, loss: 0.06317268311977386\n","epoch35, iter10, loss: 0.03560078144073486\n","epoch35, iter20, loss: 0.055497679859399796\n","epoch35, iter30, loss: 0.059810537844896317\n","epoch35, iter40, loss: 0.042116351425647736\n","epoch35, iter50, loss: 0.049114156514406204\n","epoch35, iter60, loss: 0.0472835972905159\n","Finish epoch 35, time elapsed 16.280965566635132\n","---------iter=0\n","epoch35, pix_acc: 0.9777896355065664, meanIoU: 0.8943940377830235, IoUs: [0.9291765  0.97318936 0.78081625]\n","epoch36, iter0, loss: 0.07863432914018631\n","epoch36, iter10, loss: 0.05029703304171562\n","epoch36, iter20, loss: 0.04375586658716202\n","epoch36, iter30, loss: 0.050320275127887726\n","epoch36, iter40, loss: 0.05713607743382454\n","epoch36, iter50, loss: 0.04453512281179428\n","epoch36, iter60, loss: 0.06871049106121063\n","Finish epoch 36, time elapsed 16.26136803627014\n","---------iter=0\n","epoch36, pix_acc: 0.9779156687333433, meanIoU: 0.8915462987794038, IoUs: [0.92645099 0.97341724 0.77477067]\n","epoch37, iter0, loss: 0.06785229593515396\n","epoch37, iter10, loss: 0.05611202493309975\n","epoch37, iter20, loss: 0.057709451764822006\n","epoch37, iter30, loss: 0.04649575427174568\n","epoch37, iter40, loss: 0.056624144315719604\n","epoch37, iter50, loss: 0.04855824634432793\n","epoch37, iter60, loss: 0.06477011740207672\n","Finish epoch 37, time elapsed 16.144397735595703\n","---------iter=0\n","epoch37, pix_acc: 0.9720625251130752, meanIoU: 0.8821679013806483, IoUs: [0.88526939 0.96626236 0.79497195]\n","epoch38, iter0, loss: 0.08884739875793457\n","epoch38, iter10, loss: 0.10340093821287155\n","epoch38, iter20, loss: 0.10704173892736435\n","epoch38, iter30, loss: 0.05369219928979874\n","epoch38, iter40, loss: 0.14247624576091766\n","epoch38, iter50, loss: 0.07151057571172714\n","epoch38, iter60, loss: 0.05865288898348808\n","Finish epoch 38, time elapsed 16.134517669677734\n","---------iter=0\n","epoch38, pix_acc: 0.9756244264708633, meanIoU: 0.8902017889900801, IoUs: [0.92812846 0.97058754 0.77188938]\n","epoch39, iter0, loss: 0.06826147437095642\n","epoch39, iter10, loss: 0.18037927150726318\n","epoch39, iter20, loss: 0.06608889251947403\n","epoch39, iter30, loss: 0.07140477746725082\n","epoch39, iter40, loss: 0.07412092387676239\n","epoch39, iter50, loss: 0.047315262258052826\n","epoch39, iter60, loss: 0.050490602850914\n","Finish epoch 39, time elapsed 16.15427279472351\n","---------iter=0\n","epoch39, pix_acc: 0.9762154497800144, meanIoU: 0.8880679613859934, IoUs: [0.92929838 0.9712675  0.76363801]\n","epoch40, iter0, loss: 0.04985695332288742\n","epoch40, iter10, loss: 0.04407383129000664\n","epoch40, iter20, loss: 0.06132741644978523\n","epoch40, iter30, loss: 0.040712904185056686\n","epoch40, iter40, loss: 0.053710080683231354\n","epoch40, iter50, loss: 0.058726318180561066\n","epoch40, iter60, loss: 0.06421465426683426\n","Finish epoch 40, time elapsed 16.204007148742676\n","---------iter=0\n","epoch40, pix_acc: 0.9760981489724068, meanIoU: 0.8889038263146948, IoUs: [0.93056541 0.97113999 0.76500608]\n","epoch41, iter0, loss: 0.08857626467943192\n","epoch41, iter10, loss: 0.08676592260599136\n","epoch41, iter20, loss: 0.0716714859008789\n","epoch41, iter30, loss: 0.0728452205657959\n","epoch41, iter40, loss: 0.048695433884859085\n","epoch41, iter50, loss: 0.03925558552145958\n","epoch41, iter60, loss: 0.07776124775409698\n","Finish epoch 41, time elapsed 16.121006727218628\n","---------iter=0\n","epoch41, pix_acc: 0.9768478949920457, meanIoU: 0.8911774691443174, IoUs: [0.92903155 0.97205618 0.77244468]\n","epoch42, iter0, loss: 0.044850051403045654\n","epoch42, iter10, loss: 0.06075999513268471\n","epoch42, iter20, loss: 0.08221594989299774\n","epoch42, iter30, loss: 0.0475805290043354\n","epoch42, iter40, loss: 0.08034451305866241\n","epoch42, iter50, loss: 0.058839790523052216\n","epoch42, iter60, loss: 0.043901227414608\n","Finish epoch 42, time elapsed 16.129016637802124\n","---------iter=0\n","epoch42, pix_acc: 0.9765679759300645, meanIoU: 0.8902336655298729, IoUs: [0.92849487 0.97170404 0.77050209]\n","epoch43, iter0, loss: 0.0625062957406044\n","epoch43, iter10, loss: 0.04421152547001839\n","epoch43, iter20, loss: 0.0441821813583374\n","epoch43, iter30, loss: 0.05118326470255852\n","epoch43, iter40, loss: 0.053216177970170975\n","epoch43, iter50, loss: 0.04777207598090172\n","epoch43, iter60, loss: 0.05149630084633827\n","Finish epoch 43, time elapsed 16.154796600341797\n","---------iter=0\n","epoch43, pix_acc: 0.9771777085305695, meanIoU: 0.8846243202416518, IoUs: [0.92883201 0.97261719 0.75242377]\n","epoch44, iter0, loss: 0.07371103018522263\n","epoch44, iter10, loss: 0.04174239560961723\n","epoch44, iter20, loss: 0.03699025139212608\n","epoch44, iter30, loss: 0.052260469645261765\n","epoch44, iter40, loss: 0.038123976439237595\n","epoch44, iter50, loss: 0.053631506860256195\n","epoch44, iter60, loss: 0.08562581986188889\n","Finish epoch 44, time elapsed 16.247987270355225\n","---------iter=0\n","epoch44, pix_acc: 0.9771516912352837, meanIoU: 0.8937421407783336, IoUs: [0.92779016 0.9724104  0.78102587]\n","epoch45, iter0, loss: 0.0445941723883152\n","epoch45, iter10, loss: 0.05849124491214752\n","epoch45, iter20, loss: 0.049710359424352646\n","epoch45, iter30, loss: 0.045073896646499634\n","epoch45, iter40, loss: 0.042272355407476425\n","epoch45, iter50, loss: 0.03731182962656021\n","epoch45, iter60, loss: 0.04690474644303322\n","Finish epoch 45, time elapsed 16.165812015533447\n","---------iter=0\n","epoch45, pix_acc: 0.9784028029494583, meanIoU: 0.8950413504220567, IoUs: [0.92639362 0.97398554 0.78474489]\n","epoch46, iter0, loss: 0.056874264031648636\n","epoch46, iter10, loss: 0.03918179124593735\n","epoch46, iter20, loss: 0.06786395609378815\n","epoch46, iter30, loss: 0.05886011943221092\n","epoch46, iter40, loss: 0.04013945162296295\n","epoch46, iter50, loss: 0.04034554585814476\n","epoch46, iter60, loss: 0.05401681363582611\n","Finish epoch 46, time elapsed 16.1808180809021\n","---------iter=0\n","epoch46, pix_acc: 0.9775461746181199, meanIoU: 0.8901376894690672, IoUs: [0.92496052 0.97299517 0.77245738]\n","epoch47, iter0, loss: 0.07988552004098892\n","epoch47, iter10, loss: 0.048276666551828384\n","epoch47, iter20, loss: 0.045343220233917236\n","epoch47, iter30, loss: 0.06560183316469193\n","epoch47, iter40, loss: 0.04660428687930107\n","epoch47, iter50, loss: 0.0659613236784935\n","epoch47, iter60, loss: 0.06517746299505234\n","Finish epoch 47, time elapsed 16.279486656188965\n","---------iter=0\n","epoch47, pix_acc: 0.9783768267063381, meanIoU: 0.8959496209118015, IoUs: [0.92627897 0.97392597 0.78764392]\n","epoch48, iter0, loss: 0.04601191729307175\n","epoch48, iter10, loss: 0.039875246584415436\n","epoch48, iter20, loss: 0.05143098533153534\n","epoch48, iter30, loss: 0.04107963666319847\n","epoch48, iter40, loss: 0.06053953245282173\n","epoch48, iter50, loss: 0.057424601167440414\n","epoch48, iter60, loss: 0.04929183050990105\n","Finish epoch 48, time elapsed 16.229060411453247\n","---------iter=0\n","epoch48, pix_acc: 0.9765147536165645, meanIoU: 0.8822699366023348, IoUs: [0.92476464 0.97185083 0.75019434]\n","epoch49, iter0, loss: 0.05432351306080818\n","epoch49, iter10, loss: 0.04304893687367439\n","epoch49, iter20, loss: 0.035675082355737686\n","epoch49, iter30, loss: 0.05311495065689087\n","epoch49, iter40, loss: 0.047853730618953705\n","epoch49, iter50, loss: 0.02320200763642788\n","epoch49, iter60, loss: 0.06636390835046768\n","Finish epoch 49, time elapsed 16.213861227035522\n","---------iter=0\n","epoch49, pix_acc: 0.9777317755600405, meanIoU: 0.8932299308663105, IoUs: [0.92428632 0.9731603  0.78224318]\n","The highest mIOU is 0.8959496209118015 and is achieved at epoch-48\n","The highest pixel accuracy  is 0.9784028029494583 and is achieved at epoch-46\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IbSvzMUrlGZU","colab_type":"code","outputId":"cc2510ae-096e-4166-e0bc-4fe337fd6336","executionInfo":{"status":"ok","timestamp":1579674885574,"user_tz":-480,"elapsed":976968,"user":{"displayName":"張聿程","photoUrl":"","userId":"08620233356790329924"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["epoch = list(range(len(pixel_acc_list)))\n","plt.plot(epoch, pixel_acc_list, epoch, mIOU_list)\n","plt.legend(['pixel_acc', 'mIOU'])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f27793bcf60>"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxb1Z338c9P8hZvWWxndRIHSMhK\nWJwQCLRhnUApYWmnUDqFlmXK0mGmM08JnbYUaEv7tNM+ZSa0TSllL92GTspQaBOgLE1InJCSHUJW\nOwEvcex4lSX9nj+O7CjGiWVbtuJ7f+/XS5Hu1bXuuYr0vUfn3nuOqCrGGGMGv0CqC2CMMSY5LNCN\nMcYjLNCNMcYjLNCNMcYjLNCNMcYjLNCNMcYj0rpbQEQeAS4DKlV1ZhfPC/Aj4FKgCbhBVdd197qF\nhYVaUlLS4wIbY4yfrV27tlpVi7p6rttABx4F/gt4/CjPXwJMjt3OBH4cuz+mkpISysrKEli9McaY\ndiKy+2jPddvkoqqvAgeOscgi4HF1VgHDRGRMz4tpjDGmL5LRhj4O2Bs3XR6bZ4wxZgAN6EFREblF\nRMpEpKyqqmogV22MMZ6XjECvAMbHTRfH5n2Iqi5V1VJVLS0q6rJN3xhjTC8lI9CXAZ8VZx5Qp6r7\nk/C6xhhjeiCR0xZ/CSwACkWkHLgHSAdQ1Z8Az+NOWdyOO23xc/1VWGOMMUfXbaCr6rXdPK/A7Ukr\nkTHGmF5J5Dx0Y8xRhMJRaptCDM/OICNtcF943dIWob6ljfrmcOy+jYbWMFEFVUUVorH7tKBw6vhh\nTCzIGZCyqSptEaUlHEGjEAhAWiBAIABBEYIBQRVCkSitbVFaIxFC4SihcJRI9MgxH0TcfTiqHGoJ\nc6ilLXbvbq3hCFnpQYbEblkZ7j4jLUBrW4TmtggtbRGaQxGa26K0RaIMy06nMDeTgpwMCnIzKczN\nID8rnVAkSkOre92G9nW1hpk2Op8JBdlJf58s0D1IVWlui5AeDJAWEKT9E5zE139r70FC4Sj5Wenk\nD0kjf0g6uRlpBAJCNKrUNoWoamil6tDhW1owQGFuhvvg52ZQkJPJiJwMggE54rWjseBoaAlTeaiV\nykMtVNa3UtXQSmV9K5FolJH5WYzKz2J0fhaj8jMZNTSLzLQA79e1UHGwmX0HW9h3sJn9dc1UN4QA\naF+LCAhCIADZGWnkZqaRkxkkJzONnIw0hmQECUeUUDhCKBLtCIaWcJTq2DZV1rty1Ta1ARAQKB6e\nTUlhDicU5lBSkM3EwhzCEeVAYys1jSFqGkIcaAxR3dBKY2uYlraoC4b2WyhCMCBkZ7jyZGekkZMR\nZEhGkPRggGjsvXHvkRKNHg5YJf45SAsIeVlp5GWlk5fl/n/ystJIDwSobmylpsGVo+O+MUQoHO3x\nZ2H8iCGcO7mIc08q5OwTCxmanQ5AQ2uY7ZUNvPvBIbZXNvBeVQP1LWHa4t7P9vdW1f2fBGKf0/bH\nbZEorWH3HrW0RYgOsrF4ROBo4wfdf8VM/qFgYvLXmaoRi0pLS9WuFD2sLRLlsb/uYvXOA2SkBchI\nC5CZFiAzLdjxuL3WkJUeZEhGgKy0IBFV9h1spry2/dZEeW0zTaEI4IIm/jVys9KYNW4opROHc8bE\nEZw8Ou+IQD0WVeWlrZX8aMW7vF1e96HnRSA3M43mUIRwgt8+EciIhVUkqt1+aYekB0kLCodawgm9\nfvsO5MjtcPfhaJTmUISG1jCNociHanKdZaYFKMzNpCgvk5F5mYzMz2RkXhbDczKoOtTKzupGdlU3\nsrO6kYbWD5cvOyNIQW4GI3Iyyc9KIzPNhfWQ9EDH/2skqjS1RWiKlakpFKahNUI0qgQERIRALPAC\nbs/UMR0fiuGI0tDqatrttdC2iNu+jGCAgrgda3vNMn9IurvFdgD5WenkZqYRDEhsJ3h4PU2hCKt3\nHuC1d6tZtaOGhtYwAYGTR+dT1xRiX11Lx3ZnpAWYVJDD0Ox0MtMCZAQDHZ/xjGCgI/gUt4Mi9jgt\nIGSmu895VnqQrHT3HRBxlYZI7DPTfpO4z3pGWoDM2Hrayx//fw8QjO30cjPdji8/K43crDSy0oK0\nhqNxO9owzaEooUgk7v8s2PF9TAsKB5vaqOm0ozzYFCIzPRjbsaaRm5keW1caxcOHMCw7I6HPcGci\nslZVS7t8zgI9eZpCYfYcaGJXdRO7axrZfaCJE4ty+dSc8eRmHv3H0IbyOu763dts3l/PCYXuJ2xr\nrAbT2uZqia2xmszR5GelUTw8m+LhQygenk1hXgaRiH7odQ40hnhrz0EqD7UCkJeZxqkThlE6cQSn\nFA9l5rihFOV1DkBlxRYX5Bsq6igePoTbFpxESUF2x0/0uua2jp/pOZlpsdDLoijPBWBhbgaRqFLd\nqWZY3dBKKBIlIEJQhEBAYj+hYUhGmgvOvExG5rvXan8fm0MRPqhvcbdDrXxQ10JzW4QxQ7MYN2wI\nY4cNYfTQLLLSgwn936m696qhNUxzyP26iQ+d9GDiv3RU3XburmkkIy1AQSwwEy1Lf2jfvlAkSl5m\nWlJ/tbVFovxt70Fee7eadXtqKcrN5KRRuUwemcdJI3MZP3wIacHB3Rx1PLFAT4JQOMpLWyspr22i\nvrmNutjtYOy+ora5IyTb5WelUd8SZuiQdK4/ayLXn11CQVxtsTkU4YfL3+Hh13ZQmJvJfYtmsHBm\n170mtH8hW9uih9vw2lwtfOywIQwdkp7wtqgq5bXNlO0+QNmuWtburmXbB4c6dhij8jOZNW4oM8YO\nZczQLJ58czcbK+qZMCKbO847iStPH0e6fUGNSQkL9D6orG/hqTf38NSbe6hucIEtAvlZ6Qwdcvg2\nZmgWJYU5TCzIZuKIHCYUZDN0SDpv7anlJ395jxc3fUBWeoBr5kzgpnMnsbO6ka88u4G9B5q5du4E\nFl8ytUehnGyHWtrYvK+eDRV1bIrdv1fVgCpMLMjm9vNO4srTLMiNSTUL9B5qP+j32F938fyG/bRF\nlPNOLuL6s0s4bfxw8rLcwb+e2F55iJ/+ZQfPvlWBApGoMqkwhweumsW8Ewr6Z0P6qLE1zO6aJqaM\nyrWfzMYcJyzQu7C9soGv/n4D9c3hjoNJ7Qd+GlrDvFfVSF5mGp8sHc9nz5pISWFyTs/ad7CZJ1bt\nJjczjRvPmZTSdlVjzOBzrED35WmLO6sb+fTPVhGJKqdNGNZxhL39lK8RORnccHYJV55efMyDmb0x\ndtgQ7lo4NamvaYwx4MNA313TyLVLXZg/c8s8Jo/KS3WRjDEmKXwV6OW1TXz6Z2/SEo7wy5stzI0x\n3uKbI137DjZz7c9WcailjSdvPJNpY/JTXSRjjEkqXwT6B/UtfPpnqzjY2MYTN57JzHFDU10kY4xJ\nOs8Hel1zG9f+bBVVh1p59PNzmT1+WKqLZIwx/cLzbejLN3/AjqpGHv3cHM6YODzVxTHGmH7j+Rr6\nhoo6hqQHOXeyDXlnjPE2zwf6pn11TB+bn3CPgsYYM1h5OtAjUWXTvnpmjrUzWowx3ufpQN9Z3UhT\nKGJntRhjfCGhQBeRhSKyTUS2i8jiLp6fKCIrRORtEXlFRIqTX9Se21jhBmGYVWyBbozxvm4DXUSC\nwBLgEmA6cK2ITO+02PeBx1X1FOA+4IFkF7Q3NlTUkZkW4KSi3FQXxRhj+l0iNfS5wHZV3aGqIeAZ\nYFGnZaYDL8Uev9zF8ymxsaKOaWPyretXY4wvJJJ044C9cdPlsXnx/gZcFXt8JZAnIint5DvafkB0\nnB0QNcb4Q7Kqrv8GfFRE3gI+ClQAkc4LicgtIlImImVVVVVJWnXXdh9ooqE1zCw7IGqMSUQ0Cs0H\n3S1Rtbvg3T9DONRvxeqJRK4UrQDGx00Xx+Z1UNV9xGroIpILXK2qH3pXVHUpsBTcABe9LHNCNsQO\niNoZLsb0QDgE+9bBrtdh91+hcgvkjYLhJTBsorsfXgIFJ8KwCQNfPlV3C/ShLlq/D9Y+Cjtfg5Y6\nd2utd7d2I06A8WfC+LnuvmgqBILQXAs7X4Udr8B7L0PtTrd84cnw8R/BxLOOve7aXfDq92DebTBq\nRu+34SgSCfQ1wGQRmYQL8muAT8cvICKFwAFVjQJ3A48ku6A9tbGijoxggMkjrYvc40I4BBKAoMd6\nm4hGYNdr7gufNzrVpUlMpA2aaqChEhorobEaDuyE3W9A+RoIt7jliqbBpHOhsQr2/w22PAfRtsOv\nUzwX5n0Bpl0OwaOMhxtqgq3Pweb/cYPx5o2B3FHuvcod7XYWEoC2ZmhrOvK+sRoO7XcBfGg/1O93\n99E2SM92t4xsSM+BjBwYNh5KzoUTFrhAlriLCVXdDmr1UtjyB9AoFM+BEZMgayhk5kNWvnscCUF5\nGWxfDn/7pfv7zHwYOh6qtri/zch16zrzC5BTCMu/Ab9YCGfcABfeC0M69Rl1cA+8+n1Y/xRIECac\nnZpAV9WwiNwBvAgEgUdUdZOI3AeUqeoyYAHwgIgo8Cpwe9JL2kMbK+qYOiaPjDQ7IJpSoUZY+RC8\n8SNIz4JTr4PTP+tqeIPdztfghbvhgw0QSINpH4c5N8HE+UeGSXda6uGdF2DLMmiocu9TWtwtPcsF\nSk6Ru+XG7nNGgkZcre/ATndfu8vVGhurYsNwRYFYrRaFcCs0H+iiEAKjZ8IZn4OS+TDhLBdU8aIR\nF64Hd8O+t2DNz+G3n4e8sTD3Jjj9BsgpcE0Xe/4K638Jm38PoQbIL3ahu/NVVyNOVHoO5I9xO4KJ\nZ7n7tEz3uWprcjuMUIN7vOdN2PSs+7v8cTDpI+4WboHVD0PlJsgaBmfdBqU3ujA/FlX3fu5dDXvf\ndO/rtI+7HUZx6ZE7sSkL4ZUHYNVDsO2PsPA7MONKqK9wQf7Wk+4zUfp5OOdfIH9s4u9BD3hyTFFV\nZfa9f+Ky2WP59pWz+mUdvqYKZT+H7EL34e5cGwGIhGH9k/DyA9DwPpz8MTf/nRdcCJWc62oz0z7u\nvqDJdnCP+2Jt/V/Yt97Nk9g/EnBfrvQcOOEjMOUSOPE8FziJOLAT/vw1V9MbOgEW3OWaJt56woVV\n0TSYcyPMvgYyj/ILsaXOlW/T7+G9Fa5WmDcWCk9yodvW7O7DLe7WfBAircculwRdLXV4iasFSzC2\nYxF3LwLBjMM7ho4dxEi3fGYPT++NRlz78Zs/dk0QaVku2Patc+9/Ri5MvwJOvdbVSNubSdqaoeED\nOPSB+2xArMY9xN3ShridWHaB25ElunNUhQM7XFl2vup+OTXVuOdGz4K5t8DMT7hafX/Z9xb84U73\ni2bs6fDBRleu0z8L534Jhvb9Eh3fDRK9p6aJj3zvZb595Sw+fWYK2vlSKdwKe1a5gMkpdDWBvFgN\nJz0rOetY+xj84Z/cYwm6dsaTLnS30ae40F7+Daje5tofL7oPJsxzy9fvd0G/7nH3pR8y3IV9can7\nCTxymmurjNfa4GpIu9+AXW9AU7Vrzx0xKdamO8k9joRiIf68qzWDa9ssOccFWXxtVaPudd57BVrr\nIJjpmhemLISTLnA7q/TsI5uIWg/Ba/8BK5e4Gvk5X4Kz73AhBK62uPF3sOZn7gudket+pgeCbicS\nCLr3C4X3N7jy5hfD9EUw4woYV3r0tmFVVxNtiDWRNFa6Wjgcfg+GFh+96aO/VW6FN3/iashjT4NT\nPw1TP5b4TrI/RKOuVh4Nw5hTe/arqS8iYVj9U/d+nHg+nPuvST3e4LtA/9+393P70+v4wx3nDK6r\nRN/f6GoW+WPdT8ah41zNqXPAxVOF6nfhvZdcTW/X6+7nZ1eGjHDtdp94xNXKeuPgXnjoLBh7Kpz3\nFdi+Arb/2QUYQEYehA5BwUlw4Tdg6mVdf5GiUdj5igv2HX853AyQkesCobg01u75hqv1RMMuDMee\n5t6X2t3uJ3Dnn+8SgPHz4ORLXKB017QTaXNtq++8CO/80dXw4gXSDtcY21rctp1yDVx4z9F/NqtC\nxVr3M7up2m2rRtxOJBpxj0fNdLXXcWf07QCf8R3fBfp3/riVn7++g433/h2ZaccIw+PNo5e5n4nx\nJOhq19kjjvz53H5/6AOoL3fLjjgBTrzA1TDHnuaOyMcfUKqvcM0CpZ+HS7/X8/KpwpNXu18At/3V\n1QzbNVS6ncqu11xInfYPidcW238qV6x1B+XKy+D9t902jjvdtUmXzHe1/c5NGM21sfbjnS44Tzzv\nw22/Pdm+mu1upxhqiB2ga3ZNHm3NgLrtKu7yu2TMgDhWoHvslANn0746pozKG1xhHm51YXbG59yB\ntfp9LqjrKtzj5gOHD2x17ITV/aSf9CX3067zQZ680a4Jo7OyX8BZtx8ZyIl46wn3K+DS73/4b3NH\nujbj2df07DXB7ZgKTnS3U/7ezWtrAfRwc8bRDBkO44a74O8rESic7G7GDEKeC3RVZUNFHQtnDJJT\nyNrt/5urCZ54vjvbYPTM/lnPR7/sTsV6+QG46qeJ/11dObz47+5gZumN/VO2eMlq7zfGRzzXeFdx\nsJmDTW3MGGwXFO1Z6e7bDx72l/yxcOY/wtu/gg82J/Y3qu7IfTQMl/+ntfkac5zy3Dezo8vcwRbo\nu1e6A4m9PVjZE/P/2Z0O9tL9iS2//il3kcWF93Z/7q4xJmU8F+gbKuoIBoSpowfRFaLRKOxd1f+1\n83bZI2D+P8G2591FE8dSVwEvfAUmnuPa9o0xxy3PBfrGinomj8wlK30QHRCt3ubO1phw9sCtc96t\n7krD5ffGHWTtJBqB5/7ZXWq9yJpajDneeeobqqpsrKhLfXNLJAxV78DmZe7ime4MVPt5vIwc+Mj/\ngd2vuzNXOqt+F35xCbz7p1hTywkDVzZjTK946iyX9+tbqGkM9U8Pi6FGeHyR63ej/VLp3FGxxyPd\nediVm92t6p3Dl2mXnAs3PHfs19690tWWBzo0z7gBVv6nq6WfcL6rgUcjrj+Kl77pLuW+6mcw65MD\nWy5jTK94KtA3lPdjl7mrfuzOE5+y0DWPVJS5i3rCzYeXyR/nzvs+4TwYOR3KV7tzvg+9f+ye+Pas\nch0PDdSlye3SMuC8f4dn/9F1ojRqJvzPbW47T74ULvvh4OlB0BjjrUDfWFFHQGD6mCSPUtRY43oL\nPPljcO3Th+fH96+RPcJd5BJv3OlQ9ojrgGneF7p+7bpyqNvjeoBLhVmfdNv2x7vcZfQZ2XDVwzDr\nEwO/gzHG9Imn2tA37qvnpJG5DMlI8gHR1/7DBfcFXz9yvoi7FL3gxA+HOUDRyTBqluuw6Wj2rHL3\nE7rpGL+/BIKuz5XGSph8Edz2JpzySQtzYwYhTwX6hoq65De31O52veedeh2MnNrzv595lWt6qd3d\n9fO7/+o6pBrVT1eGJmLK38G/vQufetINOGCMGZQ8E+iV9S1UHWpN/hkuL3/L9eC34O7e/f3M2NjZ\nm/676+f3rHLdz6Z6JJ/ckVYrN2aQG3Rt6L9bW84v/rrzQ/ObQm5M6qTW0Pe/DW//Gubf6bps7Y3h\nJa6f742/cyOVxGuudWfFzLiiz0U1xphBF+g5mUFG5XXdcdMZE4Yzu7iL0XN6a8W9bozBzkHcUzOv\nhhcWu9MZi6Ycnr93NaCpaz83xnjKoAv0hTPHsHDmmP5f0Y6/uP5LLv5m10Os9cT0K9zYk5v+GxYs\nPjx/z0o3gMK4M/r2+sYYQ4Jt6CKyUES2ich2EVncxfMTRORlEXlLRN4WkUuTX9QBpArL73HDg825\nue+vlz/GDYO28XdHXma/e6UbGqs/xzg0xvhGt4EuIkFgCXAJMB24VkSmd1rsq8CvVfU04BrgoWQX\ndEBtetYNe3b+vyevX+6ZV0H1O27QWHADOOxb5y4oMsaYJEikhj4X2K6qO1Q1BDwDLOq0jALtV/MM\nBfYlr4gDKBp1TS3LvwEjZ8Apn0rea09b5IaTaz8nfd86N0iwtZ8bY5IkkTb0ccDeuOly4MxOy3wD\n+JOIfBHIAS5MSukGSuVWePsZd0ZLfYXrK3zRkmMPztxTOQVuvMuNv4ML7jncIdf4AeyQyxjjack6\nKHot8Kiq/oeInAU8ISIzVTUav5CI3ALcAjBhwoQkrboP1j7q+lrZv97Vnk+6AC6+3/Vj0t1Ylr0x\n82r4/a1uMOTdK6HwZBf0xhiTBIkEegUwPm66ODYv3o3AQgBVXSkiWUAhUBm/kKouBZYClJaWHqUT\n7gFSXuaGVRs1CxZ+x4Vtf48WNPVjEMx0vwT2roaZV/bv+owxvpJIoK8BJovIJFyQXwN8utMye4AL\ngEdFZBqQBVQls6BJ135w8tqnYdgA/VrIGur6S1n3mBsQ2trPjTFJ1O1BUVUNA3cALwJbcGezbBKR\n+0Tk8thi/wrcLCJ/A34J3KB6tGFwjhNV2yA9252aOJBmXu3CHCzQjTFJlVAbuqo+Dzzfad7X4x5v\nBuYnt2j9rGorFE4Z+GHVpvwdpOe42vpA/TIwxvjCoLtSNGmqtrnRhAZaRg6cdzcEM6wzLGNMUvkz\n0Fvq3emJRSenZv1nfzE16zXGeJpnus/tkep33H1RL/o3N8aY45Q/A71qq7tPVQ3dGGP6gX8DPZjp\n+io3xhiP8GmgvxM7wyXJY48aY0wK+TTQt1pzizHGc/wX6KFGOLjHDogaYzzHf4Fe/S6gVkM3xniO\n/wK9apu7t0A3xniMDwN9qxvHc8QJqS6JMcYklQ8DfRsUnATB9FSXxBhjksqHgW5nuBhjvMlfgd7W\nArU77QwXY4wn+SvQa7aDRq2GbozxJH8FekcfLlZDN8Z4j88CfRtIwB0UNcYYj/FZoG91pyumZaa6\nJMYYk3Q+C/Rt1txijPGshAJdRBaKyDYR2S4ii7t4/ocisj52e0dEDia/qH0UDsGB9+yAqDHGs7od\ngk5EgsAS4CKgHFgjIstiA0MDoKr/Erf8F4HT+qGsfXNgB0TDUGiBbozxpkRq6HOB7aq6Q1VDwDPA\nomMsfy3wy2QULqlslCJjjMclEujjgL1x0+WxeR8iIhOBScBLfS9aklVtA8QNbGGMMR6U7IOi1wC/\nVdVIV0+KyC0iUiYiZVVVVUledTeqtsKwCZCRPbDrNcaYAZJIoFcA4+Omi2PzunINx2huUdWlqlqq\nqqVFRUWJlzIZqt+xM1yMMZ6WSKCvASaLyCQRycCF9rLOC4nIVGA4sDK5RUyCSNgNbGHt58YYD+s2\n0FU1DNwBvAhsAX6tqptE5D4RuTxu0WuAZ1RV+6eofXBwN0RarYZujPG0bk9bBFDV54HnO837eqfp\nbySvWElmfbgYY3zAH1eKdgS6neFijPEunwT6Nsgvhsy8VJfEGGP6jU8C3UYpMsZ4n/cDPRqFKjtl\n0Rjjfd4P9Lo9EG629nNjjOd5P9Brtrv7gsmpLYcxxvQz7wd6S527zy5IbTmMMaafeT/QWw+5ezvD\nxRjjcd4P9JZ6d5+Vn9pyGGNMP/N+oLceAgTSc1JdEmOM6Vf+CPTMPAh4f1ONMf7m/ZRrD3RjjPE4\nHwR6HWRa+7kxxvt8EOhWQzfG+IMFujHGeIQFujHGeIT3A72l3s5BN8b4gvcDvfWQHRQ1xviCtwM9\nGoG2RmtyMcb4QkKBLiILRWSbiGwXkcVHWebvRWSziGwSkaeTW8xesn5cjDE+0u0g0SISBJYAFwHl\nwBoRWaaqm+OWmQzcDcxX1VoRGdlfBe6R1lg/LtbkYozxgURq6HOB7aq6Q1VDwDPAok7L3AwsUdVa\nAFWtTG4xe8lq6MYYH0kk0McBe+Omy2Pz4k0BpojIGyKySkQWJquAfWKBbozxkW6bXHrwOpOBBUAx\n8KqIzFLVg/ELicgtwC0AEyZMSNKqj6Ej0K3JxRjjfYnU0CuA8XHTxbF58cqBZarapqo7gXdwAX8E\nVV2qqqWqWlpUVNTbMieufbQiOw/dGOMDiQT6GmCyiEwSkQzgGmBZp2V+j6udIyKFuCaYHUksZ+9Y\nk4sxxke6DXRVDQN3AC8CW4Bfq+omEblPRC6PLfYiUCMim4GXgf+jqjX9VeiEWaAbY3wkoTZ0VX0e\neL7TvK/HPVbgS7Hb8cNGKzLG+Ii3rxRtrXcHRG20ImOMD3g76aynRWOMj3g80Ost0I0xvuHxQLca\nujHGP7wd6NYXujHGR7wd6FZDN8b4iAW6McZ4hA8C3ZpcjDH+4N1Aj4RjoxVZoBtj/MG7gR6yy/6N\nMf7i3UC3flyMMT5jgW6MMR7h/UC389CNMT7h3UBvsQGijTH+4t1Ab20PdGtyMcb4g4cD3drQjTH+\n4oNAtyYXY4w/eDjQ6wGBDButyBjjDx4O9Nhl/yKpLokxxgwIjwe6tZ8bY/wjoUAXkYUisk1EtovI\n4i6ev0FEqkRkfex2U/KL2kOt1he6McZf0rpbQESCwBLgIqAcWCMiy1R1c6dFf6Wqd/RDGXunxYaf\nM8b4SyI19LnAdlXdoaoh4BlgUf8WKwmsycUY4zOJBPo4YG/cdHlsXmdXi8jbIvJbERmflNL1hQW6\nMcZnknVQ9A9AiaqeAvwZeKyrhUTkFhEpE5GyqqqqJK36KGxwC2OMzyQS6BVAfI27ODavg6rWqGpr\nbPJh4IyuXkhVl6pqqaqWFhUV9aa8iWu1NnRjjL8kEuhrgMkiMklEMoBrgGXxC4jImLjJy4EtySti\nL0TC0NZkNXRjjK90e5aLqoZF5A7gRSAIPKKqm0TkPqBMVZcB/yQilwNh4ABwQz+WuXs2WpExxoe6\nDXQAVX0eeL7TvK/HPb4buDu5ResD6wvdGOND3rxStMW6zjXG+I83A926zjXG+JDHA92aXIwx/uHR\nQLfh54wx/uPxQLcmF2OMf3g00K0N3RjjP94NdAnYaEXGGF/xbqBn5tloRcYYX/FmoLfU2wFRY4zv\neDPQrWMuY4wPeTTQrS90Y4z/eDjQrcnFGOMvHg50q6EbY/zFo4FubejGGP/xaKBbDd0Y4z/eC/T2\n0Yqyhqa6JMYYM6C8F+g2WpExxqe8F+g2uIUxxqe8F+jWMZcxxqcSCnQRWSgi20Rku4gsPsZyV4uI\nikhp8orYQxboxhif6jbQRSQILAEuAaYD14rI9C6WywPuBN5MdiF7pCPQ7aCoMcZfEqmhzwW2q+oO\nVQ0BzwCLuljufuC7QEsSyyGTW3EAAAxgSURBVNdzNriFMcanEgn0ccDeuOny2LwOInI6MF5V/zeJ\nZesdC3RjjE/1+aCoiASAHwD/msCyt4hImYiUVVVV9XXVXbM2dGOMTyUS6BXA+Ljp4ti8dnnATOAV\nEdkFzAOWdXVgVFWXqmqpqpYWFRX1vtTHYqMVGWN8KpFAXwNMFpFJIpIBXAMsa39SVetUtVBVS1S1\nBFgFXK6qZf1S4u601NtoRcYYX+o20FU1DNwBvAhsAX6tqptE5D4Ruby/C9hj1nWuMcan0hJZSFWf\nB57vNO/rR1l2Qd+L1QfW06Ixxqe8eaWo1dCNMT6UUA19UGmth+zCVJfCGF9ra2ujvLyclpbUXpYy\nmGVlZVFcXEx6enrCf+PBQD8EwyeluhTG+Fp5eTl5eXmUlJQgdoJCj6kqNTU1lJeXM2lS4nnm0SYX\na0M3JpVaWlooKCiwMO8lEaGgoKDHv3C8GehZ1oZuTKpZmPdNb94/bwV6pM2NVmQHRY0xPuStQLfL\n/o0x3bjpppvYvHlzr/62pKSE6urqJJcoebx1UNQC3RjTjYcffjjVReg3Hg10a3Ix5nhx7x82sXlf\nfVJfc/rYfO75+IxjLrNr1y4WLlzIGWecwbp165gxYwaPP/44l156Kd///vcpKiriwgsvZOXKlYwY\nMYKPfvSjfO1rX+Piiy/mySef5MEHHyQUCnHmmWfy0EMPEQwGuy3XFVdcwd69e2lpaeHOO+/klltu\nAeCFF17gK1/5CpFIhMLCQlasWEFDQwNf/OIXKSsrQ0S45557uPrqq/v0vngs0K3rXGPMYdu2bePn\nP/858+fP5/Of/zwPPfRQx3MTJ07krrvu4tZbb2Xu3LlMnz6diy++mC1btvCrX/2KN954g/T0dG67\n7TaeeuopPvvZz3a7vkceeYQRI0bQ3NzMnDlzuPrqq4lGo9x88828+uqrTJo0iQMHDgBw//33M3To\nUDZs2ABAbW1tn7fXY4FuNXRjjjfd1aT70/jx45k/fz4An/nMZ3jwwQePeP6mm27iN7/5DT/5yU9Y\nv349ACtWrGDt2rXMmTMHgObmZkaOHJnQ+h588EGeffZZAPbu3cu7775LVVUVH/nIRzrOJx8xYgQA\ny5cv55lnnun42+HDh/dhSx2PBrrV0I0xHz71r/N0U1MT5eXlADQ0NJCXl4eqcv311/PAAw/0aF2v\nvPIKy5cvZ+XKlWRnZ7NgwYIBv1LWY2e5xJpc7Dx0YwywZ88eVq5cCcDTTz/NOeecc8Tzd911F9dd\ndx333XcfN998MwAXXHABv/3tb6msrATgwIED7N69u9t11dXVMXz4cLKzs9m6dSurVq0CYN68ebz6\n6qvs3Lmz4/UALrroIpYsWdLx98locvFYoFsN3Rhz2Mknn8ySJUuYNm0atbW13HrrrR3P/eUvf2HN\nmjUdoZ6RkcEvfvELpk+fzje/+U0uvvhiTjnlFC666CL279/f7boWLlxIOBxm2rRpLF68mHnz5gFQ\nVFTE0qVLueqqq5g9ezaf+tSnAPjqV79KbW0tM2fOZPbs2bz88st93l5R1T6/SG+UlpZqWVmSx8BY\ncT+8/gP4+gEb4MKYFNqyZQvTpk1LaRl27drFZZddxsaNG1Najr7o6n0UkbWq+qER4cCLNXQbrcgY\n41PeOyiaOTTVpTDGHAdKSkr6pXZeU1PDBRdc8KH5K1asoKCgIOnr6wmPBbqNVmSM6V8FBQUdpzge\nbzzW5GKBbozxr4QCXUQWisg2EdkuIou7eP4LIrJBRNaLyOsiMj35RU2A9YVujPGxbgNdRILAEuAS\nYDpwbReB/bSqzlLVU4H/C/wg6SVNhPWFbozxsURq6HOB7aq6Q1VDwDPAovgFVDW+550cIDXnQloN\n3RjTA48++ih33HFHx/TSpUuZOnUqU6dOZe7cubz++usdz3XuOveVV17hsssuG9DydieRg6LjgL1x\n0+XAmZ0XEpHbgS8BGcD5SSldT7VYG7oxpneee+45fvrTn/L6669TWFjIunXruOKKK1i9ejWjR49O\ndfESkrSDoqq6RFVPBO4CvtrVMiJyi4iUiUhZVVVVslbtRNog3GwdcxljAHdh0dSpU7nhhhuYMmUK\n1113HcuXL2f+/PlMnjyZ1atXH7H8d7/7Xb73ve9RWFgIwOmnn871119/xOX5x7tEaugVwPi46eLY\nvKN5BvhxV0+o6lJgKbgrRRMsY2Ksp0Vjjk9/XAzvb0jua46eBZd8p9vFtm/fzm9+8xseeeQR5syZ\nw9NPP83rr7/OsmXL+Pa3v80VV1zRseymTZs444wzjvj70tJSHnvsseSWvR8lUkNfA0wWkUkikgFc\nAyyLX0BEJsdNfgx4N3lFTJD142KM6WTSpEnMmjWLQCDAjBkzuOCCCxARZs2axa5du3r0Wl0N2ny8\nDYTdbQ1dVcMicgfwIhAEHlHVTSJyH1CmqsuAO0TkQqANqAWu789Cd8kGtzDm+JRATbq/ZGZmdjwO\nBAId04FAgHA4fMSy06dPZ+3atZx//uFDgGvXrmXGDNefe0FBAbW1tR1NMgcOHOh4fLxIqA1dVZ9X\n1SmqeqKqfis27+uxMEdV71TVGap6qqqep6qb+rPQXbIaujGmD7785S9z1113UVNTA8D69et59NFH\nue222wBYsGABTzzxBACRSIQnn3yS8847L2Xl7Yp3Lv1vD3Q7D90Y0wuXX345FRUVnH322YgIeXl5\nPPnkk4wZMwaAr33ta9x6663Mnj0bVWXhwoV85jOfSXGpjzT4us9d9wSs/K8Pz289BPUVcPsaKJrS\n9wIaY3rteOg+1wt62n3u4KuhZ4+AopO7fi7nEhhxwsCWxxhjjhODL9CnfszdjDHGHMFbvS0aY4yP\nWaAbY/pFqo7PeUVv3j8LdGNM0mVlZVFTU2Oh3kuqSk1NDVlZWT36u8HXhm6MOe4VFxdTXl5O0vts\n8pGsrCyKi4t79DcW6MaYpEtPT2fSpEmpLobvWJOLMcZ4hAW6McZ4hAW6McZ4RMou/ReRKmB3L/+8\nEKjudilvsW32B9tmf+jLNk9U1aKunkhZoPeFiJQdrS8Dr7Jt9gfbZn/or222JhdjjPEIC3RjjPGI\nwRroS1NdgBSwbfYH22Z/6JdtHpRt6MYYYz5ssNbQjTHGdDLoAl1EForINhHZLiKLU12e/iAij4hI\npYhsjJs3QkT+LCLvxu6Hp7KMySQi40XkZRHZLCKbROTO2Hwvb3OWiKwWkb/Ftvne2PxJIvJm7PP9\nKxHJSHVZk01EgiLylog8F5v29DaLyC4R2SAi60WkLDavXz7bgyrQRSQILAEuAaYD14rI9NSWql88\nCizsNG8xsEJVJwMrYtNeEQb+VVWnA/OA22P/r17e5lbgfFWdDZwKLBSRecB3gR+q6klALXBjCsvY\nX+4EtsRN+2Gbz1PVU+NOVeyXz/agCnRgLrBdVXeoagh4BliU4jIlnaq+ChzoNHsR8Fjs8WPAFQNa\nqH6kqvtVdV3s8SHcl30c3t5mVdWG2GR67KbA+cBvY/M9tc0AIlIMfAx4ODYteHybj6JfPtuDLdDH\nAXvjpstj8/xglKrujz1+HxiVysL0FxEpAU4D3sTj2xxrelgPVAJ/Bt4DDqpqOLaIFz/f/w/4MhCN\nTRfg/W1W4E8islZEbonN65fPtnWfOwipqoqI505PEpFc4HfAP6tqvau8OV7cZlWNAKeKyDDgWWBq\niovUr0TkMqBSVdeKyIJUl2cAnaOqFSIyEviziGyNfzKZn+3BVkOvAMbHTRfH5vnBByIyBiB2X5ni\n8iSViKTjwvwpVf3v2GxPb3M7VT0IvAycBQwTkfaKltc+3/OBy0VkF6659HzgR3h7m1HVith9JW7H\nPZd++mwPtkBfA0yOHRXPAK4BlqW4TANlGXB97PH1wP+ksCxJFWtH/TmwRVV/EPeUl7e5KFYzR0SG\nABfhjh28DHwitpintllV71bVYlUtwX13X1LV6/DwNotIjojktT8GLgY20k+f7UF3YZGIXIprhwsC\nj6jqt1JcpKQTkV8CC3A9sn0A3AP8Hvg1MAHXS+Xfq2rnA6eDkoicA7wGbOBw2+pXcO3oXt3mU3AH\nw4K4itWvVfU+ETkBV3sdAbwFfEZVW1NX0v4Ra3L5N1W9zMvbHNu2Z2OTacDTqvotESmgHz7bgy7Q\njTHGdG2wNbkYY4w5Cgt0Y4zxCAt0Y4zxCAt0Y4zxCAt0Y4zxCAt0Y4zxCAt0Y4zxCAt0Y4zxiP8P\nBfE8L58g5MUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}