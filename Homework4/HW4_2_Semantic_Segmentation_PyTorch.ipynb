{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_2_Semantic_Segmentation_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MlHCEAdZPy1",
        "colab_type": "text"
      },
      "source": [
        "**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n",
        "So now you could mount your data to this ipynb!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGAXY5HMYjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTBYCMcpZoA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you mount Google drive correctly, the following commands should be able to executed correctly\n",
        "!ls /content/drive/\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/\"\n",
        "%cd \"CamVid\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWmPZKyZ8gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.vgg import VGG\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPZ7gFn0B1Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 1450\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzL2KhcaI9u",
        "colab_type": "code",
        "outputId": "306a7af1-559a-4ce4-b66d-75a6021854b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "root_dir   = \"/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/\"\n",
        "train_file = os.path.join(root_dir, \"train.csv\")\n",
        "val_file   = os.path.join(root_dir, \"val.csv\")\n",
        "\n",
        "print(\"training csv exits:{}\".format(path.exists(train_file)))\n",
        "print(\"validation csv exits:{}\".format(path.exists(val_file)))\n",
        "\n",
        "# the folder to save results for comparison\n",
        "folder_to_save_validation_result = '/content/drive/My Drive/Colab Notebooks/HW4_updated1/CamVid/result_comparision/' \n",
        "\n",
        "if os.path.isdir(folder_to_save_validation_result) == False:\n",
        "    os.mkdir(folder_to_save_validation_result)\n",
        "\n",
        "\n",
        "# the number of segmentation classes\n",
        "num_class = 12 # 32 for original CamVid\n",
        "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
        "\n",
        "h, w      = 256, 256\n",
        "train_h = 256\n",
        "train_w = 256\n",
        "val_h = 256\n",
        "val_w = 256\n",
        "\n",
        "## parameters for Solver-Adam in this example\n",
        "batch_size = 6 #\n",
        "epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n",
        "lr         = 1e-4    # achieved besty results \n",
        "step_size  = 100 # Won't work when epochs <=100\n",
        "gamma      = 0.5 # \n",
        "#\n",
        "\n",
        "## index for validation images\n",
        "global_index = 0\n",
        "\n",
        "# pixel accuracy and mIOU list \n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "num_gpu = list(range(torch.cuda.device_count()))\n",
        "\n",
        "class CamVidDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n",
        "        self.data      = pd.read_csv(csv_file)\n",
        "        self.means     = means\n",
        "        self.n_class   = n_class\n",
        "        self.flip_rate = flip_rate       \n",
        "\n",
        "        self.resize_h = h\n",
        "        self.resize_w = w        \n",
        "        \n",
        "        if phase == 'train':\n",
        "            self.new_h = train_h\n",
        "            self.new_w = train_w\n",
        "            self.crop = crop\n",
        "        elif phase == 'val':\n",
        "            self.flip_rate = 0.\n",
        "            self.crop = False # False\n",
        "            self.new_h = val_h\n",
        "            self.new_w = val_w\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name   = self.data.iloc[idx, 0]                \n",
        "        img_name = root_dir  + img_name                        \n",
        "        img = Image.open(img_name).convert('RGB')  \n",
        "\n",
        "        label_name = self.data.iloc[idx, 1]        \n",
        "        label_name = root_dir  + label_name                       \n",
        "        label_image = Image.open(label_name)\n",
        "        label = np.asarray(label_image)\n",
        "\n",
        "        # In training mode, the crop strategy is random-shift crop.\n",
        "        # In validation model, it is center crop.\n",
        "        if self.crop:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n",
        "            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n",
        "\n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        else:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = int((w - self.new_w)/2)\n",
        "            A_y_offset = int((h - self.new_h)/2)\n",
        "            \n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "\n",
        "            label_image_h, label_image_w = label_image.size\n",
        "\n",
        "        # we could try to revise the values in label for reducing the number of segmentation classes\n",
        "        label = np.array(label_image)              \n",
        "\n",
        "        if random.random() < self.flip_rate:\n",
        "            img   = np.fliplr(img)\n",
        "            label = np.fliplr(label)\n",
        "        \n",
        "        # reduce mean in terms of BGR\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= self.means[0]\n",
        "        img[1] -= self.means[1]\n",
        "        img[2] -= self.means[2]\n",
        "\n",
        "        # convert to tensor\n",
        "        img = torch.from_numpy(img.copy()).float()\n",
        "        label = torch.from_numpy(label.copy()).long()\n",
        "\n",
        "        # create one-hot encoding\n",
        "        h, w = label.size()\n",
        "        target = torch.zeros(self.n_class, h, w)\n",
        "        for c in range(self.n_class):\n",
        "            target[c][label == c] = 1\n",
        "\n",
        "        sample = {'X': img, 'Y': target, 'l': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "train_data = CamVidDataset(csv_file=train_file, phase='train')\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n",
        "val_loader = DataLoader(val_data, batch_size=1, num_workers=8)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training csv exits:True\n",
            "validation csv exits:True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h-a5moWhLhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:            \n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZWlA75uj4u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCN8s(nn.Module):\n",
        "    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n",
        "    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_d5x1O2j53K",
        "colab_type": "code",
        "outputId": "ae3acb83-472c-4732-b068-acac39adbd5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "# load pretrained weights and define FCN8s\n",
        "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
        "fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n",
        "\n",
        "ts = time.time()\n",
        "vgg_model = vgg_model.cuda()\n",
        "fcn_model = fcn_model.cuda()\n",
        "fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
        "print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma) \n",
        "\n",
        "print(fcn_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish cuda loading, time elapsed 2.0011157989501953\n",
            "DataParallel(\n",
            "  (module): FCN8s(\n",
            "    (pretrained_net): VGGNet(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (8): ReLU(inplace=True)\n",
            "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (11): ReLU(inplace=True)\n",
            "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (15): ReLU(inplace=True)\n",
            "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (18): ReLU(inplace=True)\n",
            "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (20): ReLU(inplace=True)\n",
            "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (22): ReLU(inplace=True)\n",
            "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (25): ReLU(inplace=True)\n",
            "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (27): ReLU(inplace=True)\n",
            "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (29): ReLU(inplace=True)\n",
            "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (classifier): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oExd6u7kkLw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(epoch):\n",
        "    fcn_model.eval()\n",
        "    total_ious = []\n",
        "    pixel_accs = []\n",
        "                    \n",
        "    \n",
        "    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n",
        "        if use_gpu:\n",
        "            inputs = Variable(batch['X'].cuda())\n",
        "        else:\n",
        "            inputs = Variable(batch['X'])        \n",
        "\n",
        "        output = fcn_model(inputs)                           \n",
        "        \n",
        "        # only save the 1st image for comparison\n",
        "        if iter == 0:\n",
        "            print('---------iter={}'.format(iter))\n",
        "            # generate images\n",
        "            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n",
        "            image = images[0,:,:]        \n",
        "            save_result_comparison(batch['X'], image)\n",
        "                            \n",
        "        output = output.data.cpu().numpy()\n",
        "\n",
        "        N, _, h, w = output.shape                \n",
        "        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n",
        "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
        "\n",
        "        for p, t in zip(pred, target):\n",
        "            total_ious.append(iou(p, t))\n",
        "            pixel_accs.append(pixel_acc(p, t))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
        "    ious = np.nanmean(total_ious, axis=1)\n",
        "    pixel_accs = np.array(pixel_accs).mean()\n",
        "    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n",
        "    \n",
        "    global pixel_acc_list\n",
        "    global mIOU_list\n",
        "    \n",
        "    pixel_acc_list.append(pixel_accs)\n",
        "    mIOU_list.append(np.nanmean(ious))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUjPeffKbm36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        ts = time.time()\n",
        "        for iter, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = Variable(batch['X'].cuda())\n",
        "                labels = Variable(batch['Y'].cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
        "\n",
        "            outputs = fcn_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iter % 10 == 0:\n",
        "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n",
        "        \n",
        "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
        "        \n",
        "\n",
        "        val(epoch)\n",
        "        \n",
        "    highest_pixel_acc = max(pixel_acc_list)\n",
        "    highest_mIOU = max(mIOU_list)        \n",
        "    \n",
        "    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n",
        "    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n",
        "    \n",
        "    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n",
        "    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj9aXgiYkYfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_result_comparison(input_np, output_np):\n",
        "    means     = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "    \n",
        "    global global_index\n",
        "    \n",
        "    original_im_RGB = np.zeros((256,256,3))    \n",
        "    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n",
        "    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n",
        "    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n",
        "    \n",
        "    im_seg_RGB = np.zeros((256,256,3))\n",
        "\n",
        "    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if output_np[i,j] == 0:\n",
        "                im_seg_RGB[i,j,:] = [128, 128, 128]\n",
        "            elif output_np[i,j] == 1:  \n",
        "                im_seg_RGB[i,j,:] = [128, 0, 0]\n",
        "            elif output_np[i,j] == 2:  \n",
        "                im_seg_RGB[i,j,:] = [192, 192, 128]    \n",
        "            elif output_np[i,j] == 3:  \n",
        "                im_seg_RGB[i,j,:] = [128, 64, 128]    \n",
        "            elif output_np[i,j] == 4:  \n",
        "                im_seg_RGB[i,j,:] = [0, 0, 192]    \n",
        "            elif output_np[i,j] == 5:  \n",
        "                im_seg_RGB[i,j,:] = [128, 128, 0]    \n",
        "            elif output_np[i,j] == 6:  \n",
        "                im_seg_RGB[i,j,:] = [192, 128, 128]    \n",
        "            elif output_np[i,j] == 7:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 128]    \n",
        "            elif output_np[i,j] == 8:  \n",
        "                im_seg_RGB[i,j,:] = [64, 0, 128]    \n",
        "            elif output_np[i,j] == 9:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 0]    \n",
        "            elif output_np[i,j] == 10:  \n",
        "                im_seg_RGB[i,j,:] = [0, 128, 192]    \n",
        "                    \n",
        "    # horizontally stack original image and its corresponding segmentation results     \n",
        "    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n",
        "    new_im = Image.fromarray(np.uint8(hstack_image))\n",
        "    \n",
        "    file_name = folder_to_save_validation_result + str(global_index) + '.jpg'\n",
        "        \n",
        "    global_index = global_index + 1\n",
        "        \n",
        "    new_im.save(file_name)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7cK6h9vkbf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n",
        "# Calculates class intersections over unions\n",
        "def iou(pred, target):\n",
        "    ious = []\n",
        "    for cls in range(num_class):\n",
        "        pred_inds = pred == cls\n",
        "        target_inds = target == cls\n",
        "        intersection = pred_inds[target_inds].sum()\n",
        "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n",
        "        else:\n",
        "            ious.append(float(intersection) / max(union, 1))\n",
        "        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\n",
        "    return ious\n",
        "\n",
        "\n",
        "def pixel_acc(pred, target):\n",
        "    correct = (pred == target).sum()\n",
        "    total   = (target == target).sum()\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrYQIIobkPZk",
        "colab_type": "code",
        "outputId": "e990e885-1f7d-413c-9d28-173b1aa1de6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## perform training and validation\n",
        "val(0)  # show the accuracy before training\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------iter=0\n",
            "epoch0, pix_acc: 0.029402313232421876, meanIoU: 0.007232428572301911, IoUs: [0.00000000e+00 3.50758367e-03 3.52213402e-05 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.61594298e-02 2.97810892e-02\n",
            " 3.62546482e-02 1.03479326e-03 0.00000000e+00 1.63773432e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0, iter0, loss: 0.6897113919258118\n",
            "epoch0, iter10, loss: 0.5561558604240417\n",
            "epoch0, iter20, loss: 0.41918984055519104\n",
            "epoch0, iter30, loss: 0.3384835720062256\n",
            "epoch0, iter40, loss: 0.3087167739868164\n",
            "epoch0, iter50, loss: 0.2831153869628906\n",
            "epoch0, iter60, loss: 0.2892170250415802\n",
            "Finish epoch 0, time elapsed 40.212167739868164\n",
            "---------iter=0\n",
            "epoch0, pix_acc: 0.29627304077148436, meanIoU: 0.040414828798388654, IoUs: [4.72953016e-03 1.49769712e-01 0.00000000e+00 2.97333450e-01\n",
            " 1.69851113e-03 1.36145140e-05 0.00000000e+00 1.68544374e-02\n",
            " 1.45745853e-02 0.00000000e+00 0.00000000e+00 4.10509031e-06]\n",
            "epoch1, iter0, loss: 0.25813916325569153\n",
            "epoch1, iter10, loss: 0.24514643847942352\n",
            "epoch1, iter20, loss: 0.22316715121269226\n",
            "epoch1, iter30, loss: 0.21588502824306488\n",
            "epoch1, iter40, loss: 0.19173261523246765\n",
            "epoch1, iter50, loss: 0.21087786555290222\n",
            "epoch1, iter60, loss: 0.2159208357334137\n",
            "Finish epoch 1, time elapsed 40.098435163497925\n",
            "---------iter=0\n",
            "epoch1, pix_acc: 0.5010638427734375, meanIoU: 0.10515889960401863, IoUs: [1.35067394e-01 3.24162502e-01 0.00000000e+00 7.58403028e-01\n",
            " 3.12384100e-04 1.42064680e-02 0.00000000e+00 1.10564071e-03\n",
            " 2.55446557e-02 0.00000000e+00 0.00000000e+00 3.10472246e-03]\n",
            "epoch2, iter0, loss: 0.19829142093658447\n",
            "epoch2, iter10, loss: 0.1867430955171585\n",
            "epoch2, iter20, loss: 0.1642502099275589\n",
            "epoch2, iter30, loss: 0.14963755011558533\n",
            "epoch2, iter40, loss: 0.13298936188220978\n",
            "epoch2, iter50, loss: 0.1273798942565918\n",
            "epoch2, iter60, loss: 0.11030072718858719\n",
            "Finish epoch 2, time elapsed 40.232677936553955\n",
            "---------iter=0\n",
            "epoch2, pix_acc: 0.6724411010742187, meanIoU: 0.21113578915062714, IoUs: [7.27555275e-01 4.78987883e-01 0.00000000e+00 8.35626270e-01\n",
            " 7.42261091e-03 3.63491794e-01 0.00000000e+00 2.44607214e-04\n",
            " 9.80661934e-02 0.00000000e+00 0.00000000e+00 2.22348365e-02]\n",
            "epoch3, iter0, loss: 0.13617055118083954\n",
            "epoch3, iter10, loss: 0.11107516288757324\n",
            "epoch3, iter20, loss: 0.14085060358047485\n",
            "epoch3, iter30, loss: 0.10824868083000183\n",
            "epoch3, iter40, loss: 0.08649662137031555\n",
            "epoch3, iter50, loss: 0.12223969399929047\n",
            "epoch3, iter60, loss: 0.10329314321279526\n",
            "Finish epoch 3, time elapsed 40.275208473205566\n",
            "---------iter=0\n",
            "epoch3, pix_acc: 0.7627386474609374, meanIoU: 0.2824427699960164, IoUs: [0.8694757  0.64884165 0.         0.83666469 0.13897344 0.74227114\n",
            " 0.         0.         0.1420206  0.         0.         0.01106601]\n",
            "epoch4, iter0, loss: 0.11405466496944427\n",
            "epoch4, iter10, loss: 0.09216994792222977\n",
            "epoch4, iter20, loss: 0.10509893298149109\n",
            "epoch4, iter30, loss: 0.0853738784790039\n",
            "epoch4, iter40, loss: 0.07016930729150772\n",
            "epoch4, iter50, loss: 0.07608592510223389\n",
            "epoch4, iter60, loss: 0.10825349390506744\n",
            "Finish epoch 4, time elapsed 40.2750141620636\n",
            "---------iter=0\n",
            "epoch4, pix_acc: 0.7725091552734376, meanIoU: 0.2959802597583939, IoUs: [0.8917423  0.65853952 0.         0.85822464 0.18019967 0.82275459\n",
            " 0.         0.         0.13725123 0.         0.         0.00305116]\n",
            "epoch5, iter0, loss: 0.1002696081995964\n",
            "epoch5, iter10, loss: 0.07527890056371689\n",
            "epoch5, iter20, loss: 0.08222867548465729\n",
            "epoch5, iter30, loss: 0.09439419209957123\n",
            "epoch5, iter40, loss: 0.09416560083627701\n",
            "epoch5, iter50, loss: 0.09284646064043045\n",
            "epoch5, iter60, loss: 0.06895191222429276\n",
            "Finish epoch 5, time elapsed 40.27838969230652\n",
            "---------iter=0\n",
            "epoch5, pix_acc: 0.7796395874023437, meanIoU: 0.30282243492295285, IoUs: [0.88197949 0.6994512  0.         0.87740483 0.26631927 0.73461391\n",
            " 0.         0.         0.17219852 0.         0.         0.001902  ]\n",
            "epoch6, iter0, loss: 0.08661305904388428\n",
            "epoch6, iter10, loss: 0.07347229868173599\n",
            "epoch6, iter20, loss: 0.08899114280939102\n",
            "epoch6, iter30, loss: 0.06067986041307449\n",
            "epoch6, iter40, loss: 0.06760608404874802\n",
            "epoch6, iter50, loss: 0.07177392393350601\n",
            "epoch6, iter60, loss: 0.07073284685611725\n",
            "Finish epoch 6, time elapsed 40.141119956970215\n",
            "---------iter=0\n",
            "epoch6, pix_acc: 0.8141987609863282, meanIoU: 0.3466318994337075, IoUs: [8.83960470e-01 7.29281181e-01 0.00000000e+00 8.82636636e-01\n",
            " 5.58049633e-01 7.91265490e-01 0.00000000e+00 3.06726106e-04\n",
            " 2.74482297e-01 0.00000000e+00 0.00000000e+00 3.96003606e-02]\n",
            "epoch7, iter0, loss: 0.06286389380693436\n",
            "epoch7, iter10, loss: 0.07690516859292984\n",
            "epoch7, iter20, loss: 0.08816017210483551\n",
            "epoch7, iter30, loss: 0.08098622411489487\n",
            "epoch7, iter40, loss: 0.06089475378394127\n",
            "epoch7, iter50, loss: 0.07110746949911118\n",
            "epoch7, iter60, loss: 0.1013089045882225\n",
            "Finish epoch 7, time elapsed 39.9745991230011\n",
            "---------iter=0\n",
            "epoch7, pix_acc: 0.8250457763671875, meanIoU: 0.365676470199934, IoUs: [8.84634925e-01 7.21530215e-01 8.87776677e-05 9.07374300e-01\n",
            " 5.85438264e-01 7.70704213e-01 0.00000000e+00 1.51212743e-02\n",
            " 3.71806491e-01 0.00000000e+00 0.00000000e+00 1.31419181e-01]\n",
            "epoch8, iter0, loss: 0.07919232547283173\n",
            "epoch8, iter10, loss: 0.09595786780118942\n",
            "epoch8, iter20, loss: 0.07432528585195541\n",
            "epoch8, iter30, loss: 0.08274015039205551\n",
            "epoch8, iter40, loss: 0.06335175037384033\n",
            "epoch8, iter50, loss: 0.06573271751403809\n",
            "epoch8, iter60, loss: 0.08915096521377563\n",
            "Finish epoch 8, time elapsed 40.05070900917053\n",
            "---------iter=0\n",
            "epoch8, pix_acc: 0.8122164916992187, meanIoU: 0.35544290260939954, IoUs: [8.88263222e-01 7.05188288e-01 0.00000000e+00 9.21097478e-01\n",
            " 6.60813788e-01 7.82847093e-01 0.00000000e+00 1.70389793e-03\n",
            " 2.03072823e-01 1.23272328e-04 0.00000000e+00 1.02204968e-01]\n",
            "epoch9, iter0, loss: 0.08114775270223618\n",
            "epoch9, iter10, loss: 0.05315283313393593\n",
            "epoch9, iter20, loss: 0.05744485184550285\n",
            "epoch9, iter30, loss: 0.05239775404334068\n",
            "epoch9, iter40, loss: 0.09148998558521271\n",
            "epoch9, iter50, loss: 0.0700082927942276\n",
            "epoch9, iter60, loss: 0.09288211166858673\n",
            "Finish epoch 9, time elapsed 40.02963352203369\n",
            "---------iter=0\n",
            "epoch9, pix_acc: 0.8265687561035157, meanIoU: 0.3750616772757264, IoUs: [9.10691470e-01 7.41333021e-01 0.00000000e+00 9.22617973e-01\n",
            " 6.76821863e-01 8.09893894e-01 0.00000000e+00 5.90249501e-03\n",
            " 2.70107298e-01 2.92452550e-05 0.00000000e+00 1.63342868e-01]\n",
            "epoch10, iter0, loss: 0.0677625983953476\n",
            "epoch10, iter10, loss: 0.07552248984575272\n",
            "epoch10, iter20, loss: 0.05904090404510498\n",
            "epoch10, iter30, loss: 0.06699371337890625\n",
            "epoch10, iter40, loss: 0.05857902020215988\n",
            "epoch10, iter50, loss: 0.07989886403083801\n",
            "epoch10, iter60, loss: 0.060968391597270966\n",
            "Finish epoch 10, time elapsed 39.95443630218506\n",
            "---------iter=0\n",
            "epoch10, pix_acc: 0.8362712097167969, meanIoU: 0.3817694196132339, IoUs: [0.90397098 0.74165084 0.         0.92636253 0.71510594 0.75853319\n",
            " 0.         0.0139676  0.34955563 0.         0.         0.17208633]\n",
            "epoch11, iter0, loss: 0.05288151279091835\n",
            "epoch11, iter10, loss: 0.06416016072034836\n",
            "epoch11, iter20, loss: 0.05892103165388107\n",
            "epoch11, iter30, loss: 0.044826045632362366\n",
            "epoch11, iter40, loss: 0.07860354334115982\n",
            "epoch11, iter50, loss: 0.04855719581246376\n",
            "epoch11, iter60, loss: 0.06354331970214844\n",
            "Finish epoch 11, time elapsed 39.875250816345215\n",
            "---------iter=0\n",
            "epoch11, pix_acc: 0.8317437744140626, meanIoU: 0.37849092350756086, IoUs: [9.04758135e-01 7.29008947e-01 4.76584833e-04 9.17726430e-01\n",
            " 6.61657335e-01 7.84870206e-01 0.00000000e+00 3.85721038e-03\n",
            " 3.41712063e-01 1.00503430e-04 0.00000000e+00 1.97723666e-01]\n",
            "epoch12, iter0, loss: 0.0754673033952713\n",
            "epoch12, iter10, loss: 0.06588724255561829\n",
            "epoch12, iter20, loss: 0.06824124604463577\n",
            "epoch12, iter30, loss: 0.05294622480869293\n",
            "epoch12, iter40, loss: 0.055770643055438995\n",
            "epoch12, iter50, loss: 0.05348135903477669\n",
            "epoch12, iter60, loss: 0.06205606460571289\n",
            "Finish epoch 12, time elapsed 40.025962352752686\n",
            "---------iter=0\n",
            "epoch12, pix_acc: 0.8464103698730469, meanIoU: 0.392237150905588, IoUs: [8.97690987e-01 7.59955771e-01 3.71076330e-04 9.30440419e-01\n",
            " 7.28485931e-01 7.95077116e-01 0.00000000e+00 1.05498768e-04\n",
            " 4.01398196e-01 0.00000000e+00 0.00000000e+00 1.93320815e-01]\n",
            "epoch13, iter0, loss: 0.06967263668775558\n",
            "epoch13, iter10, loss: 0.0709214061498642\n",
            "epoch13, iter20, loss: 0.05410167947411537\n",
            "epoch13, iter30, loss: 0.0700628012418747\n",
            "epoch13, iter40, loss: 0.058907974511384964\n",
            "epoch13, iter50, loss: 0.051862798631191254\n",
            "epoch13, iter60, loss: 0.054297734051942825\n",
            "Finish epoch 13, time elapsed 39.93798828125\n",
            "---------iter=0\n",
            "epoch13, pix_acc: 0.8301066589355469, meanIoU: 0.3778600951868432, IoUs: [9.00297239e-01 7.18850409e-01 1.93050193e-05 9.38019812e-01\n",
            " 7.05227635e-01 7.92547788e-01 0.00000000e+00 2.46020052e-04\n",
            " 2.91379508e-01 0.00000000e+00 0.00000000e+00 1.87733427e-01]\n",
            "epoch14, iter0, loss: 0.06168490648269653\n",
            "epoch14, iter10, loss: 0.06911785155534744\n",
            "epoch14, iter20, loss: 0.05838331952691078\n",
            "epoch14, iter30, loss: 0.06314114481210709\n",
            "epoch14, iter40, loss: 0.049268387258052826\n",
            "epoch14, iter50, loss: 0.05002020671963692\n",
            "epoch14, iter60, loss: 0.0554230622947216\n",
            "Finish epoch 14, time elapsed 40.14448690414429\n",
            "---------iter=0\n",
            "epoch14, pix_acc: 0.8414396667480468, meanIoU: 0.39083281502576944, IoUs: [9.13457553e-01 7.63051551e-01 2.70163106e-04 9.39835203e-01\n",
            " 7.11198255e-01 8.37709681e-01 0.00000000e+00 1.63472158e-02\n",
            " 3.44947791e-01 1.31926292e-04 0.00000000e+00 1.63044441e-01]\n",
            "epoch15, iter0, loss: 0.06000741198658943\n",
            "epoch15, iter10, loss: 0.05416695401072502\n",
            "epoch15, iter20, loss: 0.055279869586229324\n",
            "epoch15, iter30, loss: 0.0774001032114029\n",
            "epoch15, iter40, loss: 0.05568744242191315\n",
            "epoch15, iter50, loss: 0.051735468208789825\n",
            "epoch15, iter60, loss: 0.05210994929075241\n",
            "Finish epoch 15, time elapsed 40.17264795303345\n",
            "---------iter=0\n",
            "epoch15, pix_acc: 0.8371502685546875, meanIoU: 0.3889428339040597, IoUs: [9.10780651e-01 7.50164592e-01 1.05996845e-04 9.39364337e-01\n",
            " 7.09702976e-01 8.24645173e-01 0.00000000e+00 4.94619834e-04\n",
            " 3.65284199e-01 3.00430788e-04 3.76626556e-06 1.66467265e-01]\n",
            "epoch16, iter0, loss: 0.06095607951283455\n",
            "epoch16, iter10, loss: 0.03985302895307541\n",
            "epoch16, iter20, loss: 0.06525970995426178\n",
            "epoch16, iter30, loss: 0.05950978025794029\n",
            "epoch16, iter40, loss: 0.04596569761633873\n",
            "epoch16, iter50, loss: 0.04691419005393982\n",
            "epoch16, iter60, loss: 0.04187288507819176\n",
            "Finish epoch 16, time elapsed 40.04544234275818\n",
            "---------iter=0\n",
            "epoch16, pix_acc: 0.8510281372070313, meanIoU: 0.399161625203668, IoUs: [9.09361589e-01 7.84230908e-01 1.07905167e-03 9.36466668e-01\n",
            " 7.50609646e-01 8.09062521e-01 0.00000000e+00 2.46404619e-04\n",
            " 4.38238496e-01 1.61253464e-04 6.55326097e-05 1.60417432e-01]\n",
            "epoch17, iter0, loss: 0.05687319114804268\n",
            "epoch17, iter10, loss: 0.06828764081001282\n",
            "epoch17, iter20, loss: 0.05008332431316376\n",
            "epoch17, iter30, loss: 0.06311879307031631\n",
            "epoch17, iter40, loss: 0.050001610070466995\n",
            "epoch17, iter50, loss: 0.046883273869752884\n",
            "epoch17, iter60, loss: 0.06178688257932663\n",
            "Finish epoch 17, time elapsed 40.343220949172974\n",
            "---------iter=0\n",
            "epoch17, pix_acc: 0.838074951171875, meanIoU: 0.3981640337747175, IoUs: [9.11776238e-01 7.33855946e-01 2.80174231e-03 9.31974119e-01\n",
            " 7.23197708e-01 8.29642664e-01 0.00000000e+00 5.98935029e-04\n",
            " 4.63992349e-01 3.90700702e-04 2.71686641e-04 1.79466316e-01]\n",
            "epoch18, iter0, loss: 0.0669272318482399\n",
            "epoch18, iter10, loss: 0.04274538904428482\n",
            "epoch18, iter20, loss: 0.059128038585186005\n",
            "epoch18, iter30, loss: 0.04848228022456169\n",
            "epoch18, iter40, loss: 0.047085411846637726\n",
            "epoch18, iter50, loss: 0.052190378308296204\n",
            "epoch18, iter60, loss: 0.05642973259091377\n",
            "Finish epoch 18, time elapsed 40.450252294540405\n",
            "---------iter=0\n",
            "epoch18, pix_acc: 0.8343788146972656, meanIoU: 0.3916264001719228, IoUs: [9.12800788e-01 7.26095712e-01 2.59893470e-03 9.30642848e-01\n",
            " 7.66112830e-01 8.25095624e-01 0.00000000e+00 4.56066710e-02\n",
            " 3.21686614e-01 2.31493404e-03 7.95518055e-04 1.65766327e-01]\n",
            "epoch19, iter0, loss: 0.06004442274570465\n",
            "epoch19, iter10, loss: 0.059471990913152695\n",
            "epoch19, iter20, loss: 0.05349219590425491\n",
            "epoch19, iter30, loss: 0.048846855759620667\n",
            "epoch19, iter40, loss: 0.05717616528272629\n",
            "epoch19, iter50, loss: 0.07106377184391022\n",
            "epoch19, iter60, loss: 0.04809926450252533\n",
            "Finish epoch 19, time elapsed 40.30338382720947\n",
            "---------iter=0\n",
            "epoch19, pix_acc: 0.8290299987792968, meanIoU: 0.3865982132251807, IoUs: [9.10478569e-01 6.92678750e-01 1.20762992e-04 9.42220429e-01\n",
            " 7.48273096e-01 8.31785429e-01 0.00000000e+00 3.07360820e-02\n",
            " 3.15400186e-01 2.01091002e-03 5.65420151e-04 1.64908923e-01]\n",
            "The highest mIOU is 0.399161625203668 and is achieved at epoch-17\n",
            "The highest pixel accuracy  is 0.8510281372070313 and is achieved at epoch-17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbSvzMUrlGZU",
        "colab_type": "code",
        "outputId": "170200db-a271-41a1-f6d1-341cb54fa222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "epoch = list(range(len(pixel_acc_list)))\n",
        "plt.plot(epoch, pixel_acc_list, epoch, mIOU_list)\n",
        "plt.legend(['pixel_acc', 'mIOU'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0401c9eeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtagXocmN3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {'pixel_acc': pixel_acc_list, 'mIOU': mIOU_list}\n",
        "a = pd.DataFrame.from_dict(data)\n",
        "a.to_csv('../HW4_2_defalut.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIhgfLaUmr_2",
        "colab_type": "code",
        "outputId": "7b58ebbc-b197-4955-c706-faefbf384104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result_comparision  trainannot\ttrain.gsheet  valannot\n",
            "train\t\t    train.csv\tval\t      val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}